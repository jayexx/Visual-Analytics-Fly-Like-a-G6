---
title: "ChinaVis"
author: "SMU Student"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      include = TRUE,
                      warning = FALSE,
                      message = FALSE)

```

## Introduction

NorthClass is a well-known higher education training institution that offers over 100 courses covering various academic disciplines such as literature, science, engineering, medicine, economics, and management, attracting approximately 300,000 registered learners. The institution establishes a flexible and convenient learning environment by providing excellent instructional services. In order to adapt to the development trend of the digital age and enhance its market competitiveness in the field of technology, the institution has planned and launched a programming course. Learners are required to complete specified programming tasks during the learning period, with multiple attempts and submissions allowed to ensure full mastery and application of the knowledge learned. After the completion of the course, the organization gathers learners' temporal learning data to assess whether the quality of instruction meets the predetermined standards and requirements. To optimize teaching resources and improve teaching quality, the institution aims to establish a dedicated Smart Education Development and Innovation Group that will explore how to empower education with next-generation artificial intelligence technology, in order to better cultivate innovative talents who are suited to the development needs of the new era. Visualization and Visual Analytics harness the power of high-bandwidth visual perception channels to transform complex temporal learning behavior data into comprehensible graphical representations. These techniques not only diagnose and analyze learners' knowledge mastery levels but also dynamically monitor the evolving trends in their learning behaviors. Additionally, they effectively identify and dissect potential factors that contribute to learning difficulties. If you were a member of the Smart Education Development and Innovation Group, please design and implement a Visual Analytics solution to help the institution intuitively perceive the learning status of learners and provide feasible suggestions for adjusting teaching strategies and course designs.

## Tasks and Questions:

-   Analyze the log records of learners' question-answering behaviors, quantitatively assess the degree of knowledge mastery based on multi-dimensional attributes such as answer scores and answer status, and identify weak links in their knowledge system. (It is recommended that participants answer this question with no more than 800 words and no more than 5 pictures)

-   Mine personalized learning behavior patterns based on learners' characteristics, and design and present learners' profiles from various perspectives, including peak answering hours, preferred question types, correct answering rates, etc. (It is recommended that participants answer this question with no more than 800 words and 5 pictures)

-   Different learning modes directly impact learners' ability to absorb, integrate, and apply knowledge. Efficient learning modes can enhance deep understanding and long-term memory retention of knowledge. Please model the potential relationship between learning modes and knowledge acquisition, present the results in the form of a graph, and provide a brief analysis. (It is recommended that participants answer this question with no more than 800 words and 5 pictures)

-   The difficulty level of questions should align with the learner's level of knowledge. When a learner possesses a high level of knowledge but achieves a low percentage of correct answers, it indicates that the question's difficulty exceeds their ability. Please utilize Visual Analytics to identify these inappropriate questions. (It is recommended that participants answer this question with no more than 800 words and no more than 5 pictures)

-   Based on the outcomes of the aforementioned analysis, it is crucial to offer valuable recommendations for topic designers and course managers to optimize question bank content settings and enhance the quality of teaching and learning. Please briefly explain the rationale behind these suggestions. (It is recommended that participants answer this question with no more than 800 words and 3 pictures)

## Libraries

For this analysis, we will use the following packages from CRAN.

[`rjson`](https://cran.r-project.org/web/packages/cluster/index.html) - Methods for Cluster analysis. Much extended the original from Peter Rousseeuw, Anja Struyf and Mia Hubert, based on Kaufman and Rousseeuw (1990) "Finding Groups in Data".\
[`tidyverse`](https://www.tidyverse.org/packages/) - Loading the core tidyverse packages which will be used for data wrangling and visualisation.\
[`visNetwork`](https://cran.r-project.org/web/packages/factoextra/readme/README.html#:~:text=The%20R%20package%20factoextra%20has,data%20visualization%20with%20less%20typing.) - Extract and Visualize the Results of Multivariate Data Analyses. [`ggasym`](https://ggobi.github.io/ggally/) Extension of `ggplot2` by adding several functions to reduce the complexity of combining geometric objects with transformed data. [`igraph`](https://ggobi.github.io/ggally/) Extension of `ggplot2` by adding several functions to reduce the complexity of combining geometric objects with transformed data.

```{r}
pacman::p_load(dplyr,tidyr,stringr,readr,fs,purrr,ggplot2, plotly, ggstatsplot,igraph,lubridate,hms, tidyverse)
```

```{r}
df_StudentInfo <- read_csv("data/Data_StudentInfo.csv")
df_TitleInfo <- read_csv("data/Data_TitleInfo.csv")

```

```{r}

saveRDS(title_info_aggregated, "aggregate_title_info.RDS")
```

```{r}
csv_file_list <- dir('data/Data_SubmitRecord')
csv_file_list <- paste0("./data/Data_SubmitRecord/",csv_file_list)


df_StudentRecord <- NULL
for (file in csv_file_list) { # for every file...
  file <- read_csv(file)
    df_StudentRecord <- rbind(df_StudentRecord, file) # then stick together by rows
}
df_StudentRecord %>% glimpse()
```

```{r}
# Step 1: Identify students with multiple classes
students_multiple_classes <- df_StudentRecord %>%
  group_by(student_ID) %>%
  summarise(unique_classes = n_distinct(class)) %>%
  filter(unique_classes > 1)

# Step 2: Identify the correct class for each student (the class with the highest frequency)
correct_classes <- df_StudentRecord %>%
  filter(student_ID %in% students_multiple_classes$student_ID) %>%
  group_by(student_ID, class) %>%
  summarise(count = n()) %>%
  arrange(desc(count)) %>%
  slice(1) %>%
  select(student_ID, correct_class = class)

# Step 3: Replace wrong class values
df_StudentRecord <- df_StudentRecord %>%
  left_join(correct_classes, by = "student_ID") %>%
  mutate(class = ifelse(!is.na(correct_class), correct_class, class)) %>%
  select(-correct_class)

# Display the updated dataframe
print(df_StudentRecord)

```

```{r}

# Identify students with multiple classes
students_multiple_classes <- df_StudentRecord %>%
  group_by(student_ID) %>%
  summarise(unique_classes = n_distinct(title_ID)) %>%
  filter(unique_classes > 1)

# Display the results
print(students_multiple_classes)
```

```{r}
#remove index column
df_StudentRecord <- df_StudentRecord %>% select(-1)

#df_TitleInfo <- df_TitleInfo %>% select(-1)
#df_StudentInfo <- df_StudentInfo %>% select(-1)

```

```{r}
# Convert time from timestamp to POSIXct
df_StudentRecord$time_change <- as.POSIXct(df_StudentRecord$time, origin="1970-01-01", tz="UTC")

df_StudentRecord <- df_StudentRecord %>%
  mutate(
    time_change = ymd_hms(time_change),
    date = as.Date(time_change),
    time = as_hms(format(time_change, "%H:%M:%S")),
    score = as.factor(score),
    timeconsume = as.numeric(timeconsume)
  ) 

df_TitleInfo <- df_TitleInfo %>%
  rename (
     question_score = score
  )
```

```{r}
missing_students <- anti_join(df_StudentRecord, df_StudentInfo, by = "student_ID")

# Display the missing student IDs
missing_student_ids <- missing_students %>% select(student_ID) %>% distinct()
print(missing_student_ids)


unique(df_StudentRecord$state)

df_StudentRecord <- df_StudentRecord %>%
  filter (state != '�������')%>%
  filter (class != "class")
```

```{r}
# Self join on knowledge to find pairs of title_IDs that share knowledge
edges <- df_TitleInfo %>%
  inner_join(df_TitleInfo, by = "knowledge") %>%
  filter(title_ID.x != title_ID.y) %>%
  select(title_ID.x, title_ID.y) %>%
  distinct()
```

```{r}
# Create a graph from the edges
g <- graph_from_data_frame(edges, directed = FALSE)

# Find connected components
components <- clusters(g)

# Map the component membership back to the title_info dataframe
df_TitleInfo$domain <- components$membership[match(df_TitleInfo$title_ID, names(components$membership))]


```

```{r}
# Aggregate knowledge and sub_knowledge into lists
title_info_aggregated <- df_TitleInfo %>%
  group_by(title_ID,score) %>%
  summarise(knowledge_list = list(unique(knowledge)),
            sub_knowledge_list = list(unique(sub_knowledge)),
            .groups = 'drop')
```

```{r}
# Merge StudentInfo with SubmitRecord based on student_ID
merged_data <- merge(df_StudentRecord, df_StudentInfo, by = "student_ID")

# Merge TitleInfo with the already merged data based on title_ID
merged_data <- merge(merged_data, df_TitleInfo, by = "title_ID")

merged_data <- merged_data %>%
  rename(
    actual_score = score
  ) %>%
  mutate (actual_score = as.numeric(as.character(actual_score)))
```

### Based on point system for mastery.

If student get partially correct, award 1 point, if student get abosultely correct, award 2 points. When the student keep practicing the question, we assume he will be a master of the topic.

```{r}

adjusted_scores <- merged_data %>%
  mutate(points = case_when(
    state == "Absolutely_Correct" ~ 1,
    state == "Partially_Correct" ~ actual_score / question_score,
    TRUE ~ 0 # default case for any unexpected states
  ))

mastery_scores <- adjusted_scores %>%
  group_by(student_ID, title_ID, knowledge, class) %>%
  summarise(
    total_points = sum(points),
    total_attempts = n(),
    unique_methods = n_distinct(method),
    absolutely_correct_methods = sum(points == 1)
  ) %>%
  mutate(
    adjusted_points = total_points / total_attempts,
    adjusted_points = adjusted_points * ifelse(absolutely_correct_methods > 0, unique_methods, 1)
  )

knowledge_mastery <- mastery_scores %>%
  group_by(student_ID, class, knowledge) %>%
  summarise(total_score = sum(adjusted_points)) %>%
  left_join(df_StudentInfo %>% select(student_ID, sex, age, major), by = "student_ID") %>%
  mutate(age = as.character(age))

```

```{r}
# Create the ggplot2 boxplot
p <- ggplot(knowledge_mastery, aes(x = knowledge, y = total_score)) +
  geom_boxplot() +
  geom_jitter(width = 0.2, alpha = 0.5) +  # Adding jitter for individual points
  theme_minimal() +
  labs(
    title = "Distribution of Total Mastery Points by Knowledge",
    x = "Knowledge",
    y = "Total Mastery Points"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

p
```

```{r}
# Expand rows for questions with multiple knowledge groups
knowledge_expanded <- merged_data %>%
  separate_rows(knowledge, sep = ",") %>%
  mutate(knowledge = str_trim(knowledge))

# Identify students who have never gotten a title_ID Absolutely Correct
never_absolutely_correct <- knowledge_expanded %>%
  group_by(student_ID, title_ID, knowledge) %>%
  summarise(
    never_absolutely_correct = all(state != "Absolutely_Correct"),
    .groups = 'drop'
  ) %>%
  filter(never_absolutely_correct)


# Save processed datasets
#saveRDS(merged_data, file = "merged_data.RDS")
#saveRDS(knowledge_expanded, file = "knowledge_expanded.RDS")
#saveRDS(never_absolutely_correct, file = "never_absolutely_correct.RDS")
saveRDS(knowledge_mastery, file = "knowledge_mastery.RDS")

```

```{r}
# Calculate the total number of knowledge groups
total_knowledge_groups <- knowledge_mastery %>%
  pull(knowledge) %>%
  unique() %>%
  length()

# Calculate total scores for each student
total_scores <- knowledge_mastery %>%
  group_by(student_ID, class) %>%
  summarize(total_score = sum(total_score, na.rm = TRUE)) %>%
  ungroup()

# Calculate overall mastery by dividing the total score by the total number of knowledge groups
overall_mastery <- total_scores %>%
  mutate(overall_mastery = total_score / total_knowledge_groups) %>%
  filter (total_score > 1)  %>%
  left_join(df_StudentInfo %>% select(student_ID, sex, age, major), by = "student_ID") %>%
  mutate(age = as.character(age))

# View the overall mastery for each student
print(overall_mastery)

saveRDS(overall_mastery, file = "overall_mastery.RDS")

```

```{r}
# Calculate the error rate with consideration of different methods
percentage_correct <- merged_data %>%
  group_by(student_ID, title_ID) %>%
  summarise(
    total_attempts = n(),
    wrong_attempts = sum(state != "Absolutely_Correct"),
    percentage_wrong = (wrong_attempts / total_attempts) * 100,
    .groups = 'drop'
  )

# View the result
print(percentage_correct)

# Save processed dataset
saveRDS(percentage_correct, file = "percentage_correct.RDS")

```

```{r}
# Calculate total points and number of attempts for each student per title
attempt_scores <- merged_data %>%
  group_by(student_ID, title_ID) %>%
  summarise(total_points = sum(true_points),
            attempts = n(),
            .groups = 'drop')

# Mutate the Never_correct column
attempt_scores <- attempt_scores %>%
  mutate(Never_correct = case_when(
    total_points == -attempts ~ "yes",
    TRUE ~ "no"
  ))

# Save the attempt_scores dataframe as an RDS file
saveRDS(attempt_scores, file = "attempt_scores.RDS")

class_levels <- paste0("Class", 1:15)
domain_mastery <- merged_data %>%
  group_by(student_ID, class, domain) %>%
  summarise(average_score = mean(points), .groups = 'drop') %>%
  left_join(df_StudentInfo %>% select(student_ID, sex, age, major), by = "student_ID") %>%
  mutate(age = as.character(age)) %>%
  mutate(class = factor(class, levels = class_levels))

# Save the domain mastery dataframe as an RDS file
saveRDS(domain_mastery, file = "domain_mastery.RDS")

saveRDS(df_TitleInfo, "title_info.RDS")

```

```{r}

threshold_scores <- calculate_threshold_scores(domain_mastery, "90%")

calculate_threshold_scores <- function(domain_mastery, threshold) {
  percentile <- as.numeric(sub("%", "", threshold)) / 100
  threshold_scores <- domain_mastery %>%
    group_by(domain) %>%
    summarise(threshold_score = quantile(average_score, percentile))
  
  return(threshold_scores)
}

check <- domain_mastery %>%
    inner_join(threshold_scores, by = "domain")

get_high_mastery_students <- function(domain_mastery, threshold_scores) {
  high_mastery_students <- domain_mastery %>%
    inner_join(threshold_scores, by = "domain") %>%
    filter(average_score > threshold_score) %>%
    ungroup()
  return(high_mastery_students)
}

high_mastery_students <- get_high_mastery_students(domain_mastery, threshold_scores)

never_correct_questions <- merged_data %>%
      inner_join(high_mastery_students, by = c("student_ID", "domain", "class"), relationship = "many-to-many") %>%
      group_by(student_ID, title_ID, domain) %>%
      summarise(total_points = sum(points), attempts = n(), .groups = 'drop') %>%
      mutate(Never_correct = if_else(total_points == -attempts, "yes", "no")) %>%
      filter(Never_correct == "yes")

filtered_questions <- never_correct_questions %>%
      left_join(title_info, by = c("title_ID" = "title_ID"))
```

### Overall Mastery

```{r}

calculate_threshold_scores <- function(overall_mastery_df, threshold) {
  percentile <- as.numeric(sub("%", "", threshold)) / 100
  threshold_score <- quantile(overall_mastery_df$overall_mastery, percentile, na.rm = TRUE)
  
  return(threshold_score)
}

# Calculate threshold scores for 99% and 1%
threshold_99 <- calculate_threshold_scores(overall_mastery, "95%")
threshold_1 <- calculate_threshold_scores(overall_mastery, "5%")

# Filter high and low mastery students based on the threshold scores
high_mastery_students <- overall_mastery %>%
  filter(overall_mastery > threshold_99)

low_mastery_students <- overall_mastery %>%
  filter(overall_mastery < threshold_1)

```

```{r}

calculate_threshold_scores <- function(knowledge_mastery, threshold) {
  percentile <- as.numeric(sub("%", "", threshold)) / 100
  threshold_scores <- knowledge_mastery %>%
    group_by(knowledge) %>%
    summarise(threshold_score = quantile(total_score, percentile, na.rm = TRUE))
  
  return(threshold_scores)
}

get_high_mastery_students <- function(knowledge_mastery, threshold_scores) {
  high_mastery_students <- knowledge_mastery %>%
    inner_join(threshold_scores, by = "knowledge") %>%
    filter(total_score > threshold_score) %>%
    ungroup()
  return(high_mastery_students)
}

get_low_mastery_students <- function(knowledge_mastery, low_threshold_scores) {
  low_mastery_students <- knowledge_mastery %>%
    inner_join(low_threshold_scores, by = "knowledge") %>%
    filter(total_score < threshold_score) %>%
    ungroup()
  return(low_mastery_students)
}



threshold_scores <- calculate_threshold_scores(knowledge_mastery, "99%")
    
high_mastery_students <- get_high_mastery_students(knowledge_mastery, threshold_scores)

low_threshold_scores <- calculate_threshold_scores(knowledge_mastery, "1%")

low_mastery_students <- knowledge_mastery %>%
    inner_join(low_threshold_scores, by = "knowledge")%>%
    filter(total_score < threshold_score)%>%
    ungroup()

```

```{r, fig.width= 15}
filtered_never_correct <- never_absolutely_correct %>%
      filter(student_ID %in% high_mastery_students$student_ID) %>%
      distinct(student_ID, title_ID) %>%
      group_by(title_ID) %>%
      summarise(number_of_students = n(), .groups = 'drop') %>%
      left_join(aggregate_title_info, by = "title_ID") %>%
      mutate(percentage_of_student_wrong = (number_of_students/length(high_mastery_students$student_ID)*100)) 


bottom_percentage_never_correct <- knowledge_expanded %>%
      filter(student_ID %in% low_mastery_students$student_ID) %>%
      filter(title_ID %in% filtered_never_correct$title_ID) %>%
      filter(state == "Absolutely_Correct") %>%
      distinct(student_ID, title_ID) %>%
      group_by(title_ID) %>%
      summarise(no_of_students = n(), .groups = 'drop') %>%
      mutate(percentage_of_student_right = (no_of_students/length(low_mastery_students$student_ID)*100)) 


# Calculate percentages for high mastery and low mastery students
    high_mastery_percent <- filtered_never_correct %>%
      mutate(high_mastery = number_of_students / nrow(high_mastery_students) * 100) %>%
      select (title_ID, high_mastery)
    
    low_mastery_percent <- bottom_percentage_never_correct %>%
      mutate(low_mastery = no_of_students / nrow(low_mastery_students) * 100) %>%
      select (title_ID, low_mastery)
    
    comparison_data <- high_mastery_percent %>%
      left_join(low_mastery_percent, by = "title_ID") %>%
      mutate(diff = round(low_mastery - high_mastery, digits=2)) %>%
      pivot_longer (cols = c(low_mastery,high_mastery)) %>%
      rename (type_of_student = name,
              percentage = value)
    
    low_mastery <-  comparison_data %>%
      filter(type_of_student == "low_mastery")
    
    high_mastery <-  comparison_data %>%
      filter(type_of_student == "high_mastery")
    
    stats <- comparison_data %>%
      group_by(type_of_student) %>%
      summarise(mean = mean(percentage),
                SE = sd(percentage)) %>%
      mutate(meanpos = mean + 1 *SE,
             meanneg = mean - 1 *SE)
    
    stats_low_mastery <- stats %>%
      filter(type_of_student == "low_mastery")
    stats_high_mastery <- stats %>%
      filter(type_of_student == "high_mastery")
    
    diff <- comparison_data %>% 
      filter(type_of_student == "low_mastery") %>%
      mutate(x_pos = percentage + (-diff/2)) 
    
    comparison_spread <- comparison_data %>%
  spread(type_of_student, percentage)

# Join the stats to get the mean values
comparison_spread <- comparison_spread %>%
  left_join(stats %>% filter(type_of_student == "high_mastery") %>% select(-type_of_student), by = character()) %>%
  rename(high_mastery_mean = mean, high_mastery_SE = SE, high_mastery_meanpos = meanpos, high_mastery_meanneg = meanneg) %>%
  left_join(stats %>% filter(type_of_student == "low_mastery") %>% select(-type_of_student), by = character()) %>%
  rename(low_mastery_mean = mean, low_mastery_SE = SE, low_mastery_meanpos = meanpos, low_mastery_meanneg = meanneg)

# Create the color condition
comparison_spread <- comparison_spread %>%
  mutate(color_condition = case_when(
    high_mastery > high_mastery_mean & low_mastery > low_mastery_mean ~ "red",
    TRUE ~ "default"
  ))

# Gather the data back to long format
comparison_long <- comparison_spread %>%
      gather(type_of_student, percentage, high_mastery, low_mastery) %>%
      mutate(type_of_student = factor(type_of_student, levels = c("high_mastery", "low_mastery"))) %>%
      mutate (color_condition = ifelse(color_condition == "default", type_of_student, color_condition))

    
    
    
```

```{r}
ggplot(comparison_long) +
        geom_rect(xmin = stats_low_mastery$meanneg, xmax = stats_low_mastery$meanpos,
                  ymin = 0, ymax = 38, fill = "#762a83", alpha = .05) +
        geom_vline(xintercept = stats_low_mastery$mean, linetype = "solid", size = .5, alpha = .8, color = "#762a83")+
        
        geom_rect(xmin = stats_high_mastery$meanneg, xmax = stats_high_mastery$meanpos,
                  ymin = 0, ymax = 38, fill = "#009688", alpha = .05)+  
        geom_vline(xintercept = stats_high_mastery$mean, color = "#009688", linetype = "solid",  size = .5, alpha = .8) +
        
        
        geom_segment(data = low_mastery,
                     aes(x = percentage, y = title_ID,
                         yend = high_mastery$title_ID, xend = high_mastery$percentage),
                     color = "#aeb6bf",
                     size = 4.5,
                     alpha = 0.5) +
        geom_point(aes(x = percentage, y = title_ID, color = color_condition), size = 4, show.legend = TRUE) +
        #color points
        scale_color_manual(values = c("1" = "#009688", "2" = "#762a83", "red" = "red"))+
        #add annotations for mean and standard deviations
        geom_text(x = stats_low_mastery$mean + 5, y = 38, label = "MEAN", angle = 90, size = 2.5, color = "#009688")+
        geom_text(x = stats_low_mastery$meanpos + 5, y = 38, label = "STDEV", angle = 90, size = 2.5, color = "#009688")+
        ggtitle("Comparison of High Mastery Student Incorrectness vs Low Mastery Student Correctness") +
        geom_text (data = diff,
                   aes(label = paste("D:", diff, "%"), x = x_pos, y = title_ID),
                   fill = "white",
                   color = "#4a4e4d",
                   size = 2.5) +
        facet_grid(title_ID ~ ., scales = "free", switch = "y") +
        theme_minimal()+
        theme(panel.grid.major.y = element_blank(),
              panel.grid.minor.y = element_blank(),
              panel.grid.major.x = element_blank(),
              panel.grid.minor.x = element_blank(),
              axis.title.y = element_blank(),
              axis.text.y = element_blank(),
              axis.ticks.y = element_blank(),
              axis.ticks.x = element_line(color = "#4a4e4d"),
              text = element_text(family = "Segoe UI Semibold", color = "#4a4e4d"),
              strip.text.y.left  = element_text(angle = 0),
              panel.background = element_rect(fill = "white", color = "white"),
              strip.background = element_rect(fill = "white", color = "white"),
              strip.text = element_text(color = "#4a4e4d", family = "Segoe UI"),
              plot.background = element_rect(fill = "white", color = "white"),
              panel.spacing = unit(0, "lines"),
              plot.margin = margin(1,1,.5,1, "cm"))

```

```{r}

    stats <- comparison_data %>%
      group_by(type_of_student) %>%
      summarise(mean = mean(percentage),
                SE = sd(percentage)) %>%
      mutate(meanpos = mean + 1 *SE,
             meanneg = mean - 1 *SE)
    
    stats_low_mastery <- stats %>%
      filter(type_of_student == "low_mastery")
    stats_high_mastery <- stats %>%
      filter(type_of_student == "high_mastery")
    
    diff <- comparison_data %>% 
      filter(type_of_student == "low_mastery") %>%
      mutate(x_pos = percentage + (-diff/2)) 

```

### NEW ANALYSIS

```{r}

calculate_threshold_scores <- function(knowledge_mastery, threshold) {
  percentile <- as.numeric(sub("%", "", threshold)) / 100
  threshold_scores <- knowledge_mastery %>%
    group_by(knowledge) %>%
    summarise(threshold_score = quantile(total_mastery_points, percentile, na.rm = TRUE))
}

get_high_mastery_students <- function(knowledge_mastery, threshold_scores) {
  high_mastery_students <- knowledge_mastery %>%
    inner_join(threshold_scores, by = "knowledge") %>%
    filter(total_mastery_points > threshold_score) %>%
    ungroup()
  return(high_mastery_students)
}

get_low_mastery_students <- function(knowledge_mastery, low_threshold_scores) {
  low_mastery_students <- knowledge_mastery %>%
    inner_join(low_threshold_scores, by = "knowledge") %>%
    filter(total_mastery_points < threshold_score) %>%
    ungroup()
  return(low_mastery_students)
}

threshold_scores <- calculate_threshold_scores(knowledge_mastery, "99%")
    
high_mastery_students <- get_high_mastery_students(knowledge_mastery, threshold_scores)

low_threshold_scores <- calculate_threshold_scores(knowledge_mastery, "1%")

```

```{r}
student_question <- merged_data %>%
  group_by(student_ID, title_ID) %>%
  summarise (count = n()) %>%
  ungroup()

student_question <- student_question %>%
  group_by(student_ID) %>%
  summarise (count = n()) %>%
  filter (count >1) %>%
  ungroup()
```

```{r}

high_mastery_incorrect <- merged_data %>%
  filter(student_ID %in% high_mastery_students$student_ID) %>%
  filter(state != "Absolutely_Correct") %>%
  group_by(title_ID, knowledge) %>%
  summarise(incorrect_count = n(),
            total_attempts = n_distinct(student_ID),
            incorrect_percentage = incorrect_count / total_attempts * 100,
            .groups = 'drop')

# Plot: Incorrect Attempts by High Mastery Students
ggplot(high_mastery_incorrect, aes(x = knowledge, y = title_ID, fill = incorrect_percentage)) +
  geom_tile() +
  scale_fill_gradient(low = "lightblue", high = "red") +
  theme_minimal() +
  labs(title = "Incorrect Attempts by High Mastery Students", x = "Knowledge Group", y = "Title ID", fill = "Incorrect %")



```

```{r}
percentage_high_mastery <- percentage_correct %>%
  filter(student_ID %in% high_mastery_students$student_ID) %>%
  group_by(title_ID) %>%
  summarise (mean = mean(percentage_wrong), n = n())
  



```

```{r}

# Data Cleaning and Preparation
biserial_data <- adjusted_scores %>%
  filter(student_ID %in% high_mastery_students$student_ID) %>%
  group_by(title_ID) %>%
  summarise(biserial_correlation = biserial.cor(adjusted_total_points, as.numeric(adjusted_total_points > 0)), .groups = 'drop')

# Plot: Biserial Correlation
plot8 <- ggplot(biserial_data, aes(x = reorder(title_ID, biserial_correlation), y = biserial_correlation)) +
  geom_bar(stat = "identity", fill = "purple") +
  theme_minimal() +
  labs(title = "Biserial Correlation", x = "Title ID", y = "Biserial Correlation")

plotly::ggplotly(plot8)

```

```{r}
first_attempt_data <- merged_data %>%
  group_by(student_ID, title_ID) %>%
  slice(1) %>%
  mutate (true_points = case_when(
      state == "Absolutely_Correct" ~ 1,
      TRUE ~ 0
    )) %>%
  select (student_ID, title_ID, true_points)

first_attempt_long <- pivot_wider(first_attempt_data, 
                                   names_from = title_ID, values_from = true_points) %>%
  filter (student_ID %in% student_question$student_ID)
  


```

```{r}
library (mirt)
first_attempt_long <- first_attempt_long %>%
  mutate_all(~ replace_na(., 0))

saveRDS(first_attempt_long, "mirtdata.RDS")  


first_attempt_long_high <- first_attempt_long %>%
  filter(student_ID %in% high_mastery_students$student_ID | student_ID %in% low_mastery_students$student_ID)

fit3PL <- mirt(data = first_attempt_long_high[2:39], 
               model = 1,  # alternatively, we could also just specify model = 1 in this case
               itemtype = "2PL",
               SE = TRUE,
               verbose = FALSE)
fit3PL

```

```{r}
summary(fit3PL)
```

```{r}
M2(fit3PL, type = "C2", calcNULL = FALSE)

```

```{r}

params3PL <- coef(fit3PL, IRTpars = TRUE, simplify = TRUE)
round(params3PL$items, 2) # g = c = guessing parameter

```

```{r, fig.height=12}

itemfit(fit3PL)

itemfitPlot(fit3PL)

```

```{r}

IRT_parms <- coef(mod1, IRTpars = TRUE, simplify = TRUE)
IRT_parms$items
```

```{r, fig.height= 15}
plot(fit3PL, type='trace', which.item = c(1:38), facet_items=T, 
     as.table = TRUE, auto.key=list(points=F, lines=T, columns=4, space = 'top', cex = .8), 
              theta_lim = c(-3, 3), 
     main = "")

```

```{r}

plot(fit3PL, type='infotrace', which.item = c(1:38), facet_items=T, 
     as.table = TRUE, auto.key=list(points=F, lines=T, columns=1, space = 'right', cex = .8), 
              theta_lim = c(-3, 3), 
     main="")

```

```{r}
itemfitPlot <- function(model,
                        fit_stats = "infit",
                        color = "red",
                        shape = 17,
                        title = "Item Infit and Outfit Statistics",
                        ...) {
    
  
    fit <- mirt::itemfit(model, fit_stats = fit_stats, ...)
    
    if("infit" %in% names(fit)) {
      fit %>%
        select(item, infit, outfit) %>%
        gather(key, value, -item) %>%
        ggplot(aes(x = item, y = value)) +
        geom_point(size = 3, color = color, shape = shape) +
        geom_line() +
        geom_hline(yintercept = .5, color = "darkgrey", linetype = "dashed") +
        geom_hline(yintercept = 1, color = "darkgrey") +
        geom_hline(yintercept = 1.5, color = "darkgrey", linetype = "dashed") +
        scale_y_continuous(breaks = c(.5, 1, 1.5), limits = c(0, 2)) +
        facet_grid(~key) +
        coord_flip() +
        theme_minimal() +
        labs(y = "", x = "", caption = "Note: Items with values within 0.5 and 1.5 are considered to be productive for measurement.",
             title = title)
    }
}

```

```{r, fig.height=15}

tracePlot(fit3PL)

itempersonMap(fit3PL)


```

```{r}

tracePlot <- function(model, 
                      items = NULL,
                      theta_range = c(-4,4),
                      title = "Item Characteristics Curves",
                      n.answers = 5,
                      facet = TRUE,
                      legend = FALSE) {
  
  data <- model@Data$data %>% as.data.frame
  
  # Set theta range as sequence
  theta_range = seq(theta_range[1], theta_range[2], by = .01)
  
  # Check model type
  type <- model@Model$itemtype
  
  # Graded response model
  if(type[1] == "graded") {
    
    trace <- probtrace(model, Theta = theta_range) %>%
      as_tibble %>%
      mutate(Theta = theta_range) %>%
      gather(key, value, -Theta) %>%
      separate(key, c("var", "response"), sep = ifelse(n.answers > 10, -4, -3))
    
    p <- ggplot(trace, aes(x = Theta, y =  value)) +
      geom_line(aes(color = response)) +
      facet_wrap(~var) +
      theme_minimal() +
      labs(x = expression(theta), 
           y = expression(P(theta)), 
           title = title) +
      scale_color_brewer(palette = 7)
    
  } else {
  
  trace <- NULL
  for(i in 1:length(data)){
  extr <- extract.item(model, i)
  theta <- matrix(theta_range)
  trace[[i]] <- probtrace(extr, theta)
  }
  
  if (!is.null(items)) {
    trace <- trace[items]
  }
  
  names(trace) <- paste('item', 1:length(trace))
  trace_df <- do.call(rbind, trace)
  
  item <- rep(names(trace), each = length(theta))
  d <- cbind.data.frame(theta, item, trace_df)
  d$item <- as.factor(d$item)
  
  # final plot
  if(isFALSE(facet)) {
  p <- ggplot(d, aes(theta, P.1, colour = item)) + 
    geom_line() + 
    labs(x = expression(theta), 
         y = expression(P(theta)), 
         title = title) +
    theme_minimal() +
    scale_color_brewer(palette = 7)
  
  if(isFALSE(legend)) {
   p <- p + guides(color = "none")
  }
    
  } else {
   p <- ggplot(d, aes(theta, P.1)) + 
      geom_line() + 
      facet_wrap(~item) +
      labs(x = expression(theta), 
           y = expression(P(theta)), 
           title = title) +
      theme_minimal()
  }
  
  }
  return(p)
}



```

```{r}
itempersonMap <- function(model,
                          theta_range = c(-4,4),
                          title = "Item Person Map",
                          margin = c(1,0,-1.5,0),
                          density = FALSE,
                          color = "red",
                          shape = 17,
                          size = 3,
                          theme = theme_minimal(),
                          ...) {
  
  p1 <- personDist(model, theta_range = theta_range, density = density) + 
    theme + 
    theme(plot.margin = unit(margin,"cm")) + 
    labs(title = title)
  p2 <- itemDist(model, theta_range = theta_range, shape = shape, color = color, size = size, ...) + 
    theme
  
  
  p <- cowplot::plot_grid(p1, p2,
                          nrow = 2,
                          rel_heights = c(1.5,2.5),
                          align = "hv",
                          axis = "tlbr")
  
  return(p)
}

personDist <- function(model, 
                       theta_range = c(-4, 4),
                       density = FALSE,
                       bins = 35) {
  
  person.params <- fscores(model, QMC = TRUE) %>%
    as.data.frame() 
  
  if(length(person.params) != 1) {
    p <- person.params %>%
      tidyr::pivot_longer(names(.), names_to = "dimension") %>%
      ggplot(aes(x = value, fill = dimension)) 
      
  } else {
  
  p <- person.params %>%
    pivot_longer(names(.), names_to = "dimension") %>%
    ggplot(aes(x = value, fill = dimension)) +
    guides(fill = "none")
  }
  
  if(isTRUE(density)) {
    
    p <- p + geom_density()
    
  } else {
    
    p <- p + geom_histogram(bins = bins, color = "white")
  }

  
  p + xlim(theta_range) + theme_minimal() + labs(x = expression(theta))
  
}

itemDist <- function(model,
                     theta_range = c(-4, 4),
                     ...) {
  
  item.params <- mirt::coef(model, IRTpars = TRUE, simplify = TRUE) %>%
    as.data.frame %>%
    tibble::rownames_to_column("items") 
  
  p <- item.params %>%
    mutate(items = forcats::fct_reorder(items, items.b)) %>%
    ggplot(aes(y = items, x = items.b)) + 
    geom_point(...)
  
  p + xlim(theta_range) + theme_minimal() + labs(x = expression(theta), y = "")
}

```

```{r}

percentage_correct <- percentage_correct %>%
  filter (student_ID %in% high_mastery_students$student_ID) %>%
  group_by(title_ID) %>%
  summarise (avg_percentage_wrong = mean(percentage_wrong))

percentile_75 <- quantile(percentage_correct$avg_percentage_wrong, 0.75)

percentage_correct <- percentage_correct %>%
    mutate(highlight = ifelse(avg_percentage_wrong > percentile_75, "Above 75 Percentile", "Below 75 Percentile"))

ggplot(percentage_correct, aes(x = reorder(title_ID,avg_percentage_wrong), y = avg_percentage_wrong, color = highlight)) +
  geom_segment(aes(x = title_ID, xend = title_ID, y = 0, yend = avg_percentage_wrong), color = "grey") +
  geom_point(size = 4, alpha = 0.8) +
  scale_color_manual(values = c("Above 75 Percentile" = "red", "Below 75 Percentile" = "blue"), name = "Error Quantile") +
  labs(
    title = "Average Error Rate per Question for High Mastery Students",
    x = "Title ID",
    y = "Percentage of Error Rate"
  ) +
  theme_light() +
  coord_flip() +
  theme(
    panel.grid.major.y = element_blank(),
    panel.border = element_blank(),
    axis.ticks.y = element_blank(),    
    axis.title.y = element_text(size = 14, color = "black"),
    axis.title.x = element_text(size = 14, color = "black"),
    plot.title = element_text(size = 14, hjust = 0.5, face = "bold", color = "black"),
    legend.title = element_text(size = 10),
    legend.text = element_text(size = 10),
    legend.position = "bottom",
    panel.spacing.x = unit(1, "cm")
  )


ggsave("percentage_correct.png" , width = 30, height = 15, units = "cm")
```
