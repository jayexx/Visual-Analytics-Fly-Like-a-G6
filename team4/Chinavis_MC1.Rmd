---
title: "ChinaVis"
author: "SMU Student"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      include = TRUE,
                      warning = FALSE,
                      message = FALSE)

```

## Introduction

NorthClass is a well-known higher education training institution that offers over 100 courses covering various academic disciplines such as literature, science, engineering, medicine, economics, and management, attracting approximately 300,000 registered learners. The institution establishes a flexible and convenient learning environment by providing excellent instructional services. In order to adapt to the development trend of the digital age and enhance its market competitiveness in the field of technology, the institution has planned and launched a programming course. Learners are required to complete specified programming tasks during the learning period, with multiple attempts and submissions allowed to ensure full mastery and application of the knowledge learned. After the completion of the course, the organization gathers learners' temporal learning data to assess whether the quality of instruction meets the predetermined standards and requirements. To optimize teaching resources and improve teaching quality, the institution aims to establish a dedicated Smart Education Development and Innovation Group that will explore how to empower education with next-generation artificial intelligence technology, in order to better cultivate innovative talents who are suited to the development needs of the new era. Visualization and Visual Analytics harness the power of high-bandwidth visual perception channels to transform complex temporal learning behavior data into comprehensible graphical representations. These techniques not only diagnose and analyze learners' knowledge mastery levels but also dynamically monitor the evolving trends in their learning behaviors. Additionally, they effectively identify and dissect potential factors that contribute to learning difficulties. If you were a member of the Smart Education Development and Innovation Group, please design and implement a Visual Analytics solution to help the institution intuitively perceive the learning status of learners and provide feasible suggestions for adjusting teaching strategies and course designs.

## Tasks and Questions:

-   Analyze the log records of learners' question-answering behaviors, quantitatively assess the degree of knowledge mastery based on multi-dimensional attributes such as answer scores and answer status, and identify weak links in their knowledge system. (It is recommended that participants answer this question with no more than 800 words and no more than 5 pictures)

-   Mine personalized learning behavior patterns based on learners' characteristics, and design and present learners' profiles from various perspectives, including peak answering hours, preferred question types, correct answering rates, etc. (It is recommended that participants answer this question with no more than 800 words and 5 pictures)

-   Different learning modes directly impact learners' ability to absorb, integrate, and apply knowledge. Efficient learning modes can enhance deep understanding and long-term memory retention of knowledge. Please model the potential relationship between learning modes and knowledge acquisition, present the results in the form of a graph, and provide a brief analysis. (It is recommended that participants answer this question with no more than 800 words and 5 pictures)

-   The difficulty level of questions should align with the learner's level of knowledge. When a learner possesses a high level of knowledge but achieves a low percentage of correct answers, it indicates that the question's difficulty exceeds their ability. Please utilize Visual Analytics to identify these inappropriate questions. (It is recommended that participants answer this question with no more than 800 words and no more than 5 pictures)

-   Based on the outcomes of the aforementioned analysis, it is crucial to offer valuable recommendations for topic designers and course managers to optimize question bank content settings and enhance the quality of teaching and learning. Please briefly explain the rationale behind these suggestions. (It is recommended that participants answer this question with no more than 800 words and 3 pictures)

## Libraries

For this analysis, we will use the following packages from CRAN.

[`rjson`](https://cran.r-project.org/web/packages/cluster/index.html) - Methods for Cluster analysis. Much extended the original from Peter Rousseeuw, Anja Struyf and Mia Hubert, based on Kaufman and Rousseeuw (1990) "Finding Groups in Data".\
[`tidyverse`](https://www.tidyverse.org/packages/) - Loading the core tidyverse packages which will be used for data wrangling and visualisation.\
[`visNetwork`](https://cran.r-project.org/web/packages/factoextra/readme/README.html#:~:text=The%20R%20package%20factoextra%20has,data%20visualization%20with%20less%20typing.) - Extract and Visualize the Results of Multivariate Data Analyses. [`ggasym`](https://ggobi.github.io/ggally/) Extension of `ggplot2` by adding several functions to reduce the complexity of combining geometric objects with transformed data. [`igraph`](https://ggobi.github.io/ggally/) Extension of `ggplot2` by adding several functions to reduce the complexity of combining geometric objects with transformed data.

```{r}
pacman::p_load(dplyr,tidyr,stringr,readr,fs,purrr,ggplot2, plotly, ggstatsplot,igraph,lubridate,hms, vcd)
```

```{r}
df_StudentInfo <- read_csv("data/Data_StudentInfo.csv")
df_TitleInfo <- read_csv("data/Data_TitleInfo.csv")

```

```{r}

saveRDS(title_info_aggregated, "aggregate_title_info.RDS")
```

```{r}
csv_file_list <- dir('data/Data_SubmitRecord')
csv_file_list <- paste0("./data/Data_SubmitRecord/",csv_file_list)


df_StudentRecord <- NULL
for (file in csv_file_list) { # for every file...
  file <- read_csv(file)
    df_StudentRecord <- rbind(df_StudentRecord, file) # then stick together by rows
}
df_StudentRecord %>% glimpse()
```

```{r}
# Step 1: Identify students with multiple classes
students_multiple_classes <- df_StudentRecord %>%
  group_by(student_ID) %>%
  summarise(unique_classes = n_distinct(class)) %>%
  filter(unique_classes > 1)

# Step 2: Identify the correct class for each student (the class with the highest frequency)
correct_classes <- df_StudentRecord %>%
  filter(student_ID %in% students_multiple_classes$student_ID) %>%
  group_by(student_ID, class) %>%
  summarise(count = n()) %>%
  arrange(desc(count)) %>%
  slice(1) %>%
  select(student_ID, correct_class = class)

# Step 3: Replace wrong class values
df_StudentRecord <- df_StudentRecord %>%
  left_join(correct_classes, by = "student_ID") %>%
  mutate(class = ifelse(!is.na(correct_class), correct_class, class)) %>%
  select(-correct_class)

# Display the updated dataframe
print(df_StudentRecord)

```

```{r}

# Identify students with multiple classes
students_multiple_classes <- df_StudentRecord %>%
  group_by(student_ID) %>%
  summarise(unique_classes = n_distinct(title_ID)) %>%
  filter(unique_classes > 1)

# Display the results
print(students_multiple_classes)
```

```{r}
#remove index column
#df_StudentRecord <- df_StudentRecord %>% select(-1)
df_TitleInfo <- df_TitleInfo %>% select(-1)
df_StudentInfo <- df_StudentInfo %>% select(-1)

```

```{r}
# Convert time from timestamp to POSIXct
df_StudentRecord$time_change <- as.POSIXct(df_StudentRecord$time, origin="1970-01-01", tz="UTC")

df_StudentRecord <- df_StudentRecord %>%
  mutate(
    time_change = ymd_hms(time_change),
    date = as.Date(time_change),
    time = as_hms(format(time_change, "%H:%M:%S")),
    score = as.factor(score),
    timeconsume = as.numeric(timeconsume)
  ) 

df_TitleInfo <- df_TitleInfo %>%
  rename (
     question_score = score
  )
```

```{r}
missing_students <- anti_join(df_StudentRecord, df_StudentInfo, by = "student_ID")

# Display the missing student IDs
missing_student_ids <- missing_students %>% select(student_ID) %>% distinct()
print(missing_student_ids)


unique(df_StudentRecord$state)

df_StudentRecord <- df_StudentRecord %>%
  filter (state != '�������')%>%
  filter (class != "class")
```

```{r}
# Self join on knowledge to find pairs of title_IDs that share knowledge
edges <- df_TitleInfo %>%
  inner_join(df_TitleInfo, by = "knowledge") %>%
  filter(title_ID.x != title_ID.y) %>%
  select(title_ID.x, title_ID.y) %>%
  distinct()
```

```{r}
# Create a graph from the edges
g <- graph_from_data_frame(edges, directed = FALSE)

# Find connected components
components <- clusters(g)

# Map the component membership back to the title_info dataframe
df_TitleInfo$domain <- components$membership[match(df_TitleInfo$title_ID, names(components$membership))]


```

```{r}
# Aggregate knowledge and sub_knowledge into lists
title_info_aggregated <- df_TitleInfo %>%
  group_by(title_ID,score) %>%
  summarise(knowledge_list = list(unique(knowledge)),
            sub_knowledge_list = list(unique(sub_knowledge)),
            .groups = 'drop')
```

```{r}
# Merge StudentInfo with SubmitRecord based on student_ID
merged_data <- merge(df_StudentRecord, df_StudentInfo, by = "student_ID")

# Merge TitleInfo with the already merged data based on title_ID
merged_data <- merge(merged_data, df_TitleInfo, by = "title_ID")

merged_data <- merged_data %>%
  rename(
    actual_score = score
  ) %>%
  mutate (actual_score = as.numeric(as.character(actual_score)))
```

### Based on point system for mastery.

If student get partially correct, award 1 point, if student get abosultely correct, award 2 points. When the student keep practicing the question, we assume he will be a master of the topic.


```{r}

merged_data <- merged_data %>%
  mutate(true_points = case_when(
    state == "Absolutely_Correct" ~ 2,
    state == "Partially_Correct" ~ question_score / actual_score,
    TRUE ~ -1
  )) 

# Expand rows for questions with multiple knowledge groups
knowledge_expanded <- merged_data %>%
  separate_rows(knowledge, sep = ",") %>%
  mutate(knowledge = str_trim(knowledge))

# Identify students who have never gotten a title_ID Absolutely Correct
never_absolutely_correct <- knowledge_expanded %>%
  group_by(student_ID, title_ID, knowledge) %>%
  summarise(
    never_absolutely_correct = all(state != "Absolutely_Correct"),
    .groups = 'drop'
  ) %>%
  filter(never_absolutely_correct)

# Calculate knowledge mastery scores for each student
knowledge_mastery <- knowledge_expanded %>%
  group_by(student_ID, class, knowledge) %>%
  summarise(average_score = mean(true_points), .groups = 'drop') %>%
  left_join(df_StudentInfo %>% select(student_ID, sex, age, major), by = "student_ID") %>%
  mutate(age = as.character(age))

# Save processed datasets
saveRDS(merged_data, file = "merged_data.RDS")
saveRDS(knowledge_expanded, file = "knowledge_expanded.RDS")
saveRDS(never_absolutely_correct, file = "never_absolutely_correct.RDS")
saveRDS(knowledge_mastery, file = "knowledge_mastery.RDS")

```

```{r}

# Identify students who have never gotten a title_ID Absolutely Correct
never_absolutely_correct <- merged_data %>%
  group_by(student_ID, title_ID) %>%
  summarise(
    never_absolutely_correct = all(state != "Absolutely_Correct"),
    .groups = 'drop'
  ) %>%
  filter(never_absolutely_correct)

```


```{r}
saveRDS(merged_data, "merged_data_df.rds")
#merged_data <- readRDS("merged_data_df.rds")
```

```{r}
summary (merged_data)
```

```{r}
df_StudentRecord_duplicate <- merged_data %>%
  group_by(student_ID, title_ID) %>%
  arrange(student_ID, title_ID, time) %>%
  mutate(cumulative_correct = cumsum(state == "Absolutely_Correct")) %>%
  filter(cumulative_correct <= 1) %>%
  ungroup() %>%
  select(-cumulative_correct)

```

## Assign Points and Calculate Weighted Scores

Calculate the total points and weighted score for each student per title, and then compute the overall performance for each student.

```{r}

# Calculate total points and number of attempts for each student per title
attempt_scores <- merged_data %>%
  group_by(student_ID, title_ID) %>%
  summarise(total_points = sum(points),
            attempts = n(),
            .groups = 'drop')

# Calculate the weighted score by dividing total points by number of attempts
attempt_scores <- attempt_scores %>%
  mutate(weighted_score = total_points / attempts)

# Calculate the overall weighted score for each student
overall_weighted_score <- attempt_scores %>%
  group_by(student_ID) %>%
  summarise(overall_weighted_score = mean(weighted_score, na.rm = TRUE), .groups = 'drop')

# Calculate the completion rate for each student (number of titles attempted)
completion_rate <- merged_data %>%
  group_by(student_ID) %>%
  summarise(titles_attempted = n_distinct(title_ID), .groups = 'drop')

# Merge all metrics
student_performance <- overall_weighted_score %>%
  left_join(completion_rate, by = "student_ID") %>%
  left_join(df_StudentInfo %>% select(student_ID, major), by = "student_ID") %>%
  left_join(merged_data %>% select(student_ID, class) %>% distinct(), by = "student_ID") %>%
  filter (titles_attempted > 7) ## There are only 2 students who attempted 1 question, we will remove them from the analysis


```

```{r}
check_partially <- merged_data %>%
  filter (state == "Partially_Correct")

print(unique(check_partially$actual_score))
```

## Assign True Points and Calculate Weighted Scores

```{r}

# Calculate total points and number of attempts for each student per title
attempt_scores_true <- merged_data %>%
  group_by(student_ID, title_ID) %>%
  summarise(total_points = sum(true_points),
            attempts = n(),
            .groups = 'drop')

# Calculate the weighted score by dividing total points by number of attempts
attempt_scores_true <- attempt_scores_true %>%
  mutate(weighted_score = total_points / attempts)

# Calculate the overall weighted score for each student
overall_weighted_score_true <- attempt_scores_true %>%
  group_by(student_ID) %>%
  summarise(overall_weighted_score = mean(weighted_score, na.rm = TRUE), .groups = 'drop')

# Calculate the completion rate for each student (number of titles attempted)
completion_rate_true <- merged_data %>%
  group_by(student_ID) %>%
  summarise(titles_attempted = n_distinct(title_ID), .groups = 'drop')

# Merge all metrics
student_performance_true <- overall_weighted_score %>%
  left_join(completion_rate_true, by = "student_ID") %>%
  left_join(df_StudentInfo %>% select(student_ID, major), by = "student_ID") %>%
  left_join(merged_data %>% select(student_ID, class) %>% distinct(), by = "student_ID") %>%
  filter (titles_attempted > 7) ## There are only 2 students who attempted 1 question, we will remove them from the analysis


```

## Calculate Performance Metrics

Determine the performance metrics for each student within each domain.

```{r}

# Calculate the total points and number of attempts for each student per title in each domain
attempt_scores_domain <- merged_data %>%
  group_by(domain, student_ID, title_ID) %>%
  summarise(total_points = sum(points),
            attempts = n(),
            .groups = 'drop')

# Calculate the weighted score by dividing total points by number of attempts for each domain
attempt_scores_domain <- attempt_scores_domain %>%
  mutate(weighted_score = total_points / attempts)

# Calculate the overall weighted score for each student within each domain
overall_weighted_score_domain <- attempt_scores_domain %>%
  group_by(domain, student_ID) %>%
  summarise(overall_weighted_score = mean(weighted_score, na.rm = TRUE), .groups = 'drop')

# Calculate the completion rate for each student within each domain (number of titles attempted)
completion_rate_domain <- merged_data %>%
  group_by(domain, student_ID) %>%
  summarise(titles_attempted = n_distinct(title_ID), .groups = 'drop')

# Merge all metrics for each domain
student_performance_domain <- overall_weighted_score_domain %>%
  left_join(completion_rate_domain, by = c("domain", "student_ID"))

```

Determine the True_Score performance metrics for each student within each domain.

```{r}

# Calculate the total points and number of attempts for each student per title in each domain
attempt_scores_domain_true <- merged_data %>%
  group_by(domain, student_ID, title_ID) %>%
  summarise(total_points = sum(true_points),
            attempts = n(),
            .groups = 'drop')

# Calculate the weighted score by dividing total points by number of attempts for each domain
attempt_scores_domain_true <- attempt_scores_domain_true %>%
  mutate(weighted_score = total_points / attempts,
         Never_correct = case_when(
           total_points == -attempts ~ "yes",
           TRUE ~ "no"
         ))

# Calculate the overall weighted score for each student within each domain
overall_weighted_score_domain_true <- attempt_scores_domain_true %>%
  group_by(domain, student_ID) %>%
  summarise(overall_mean_score = mean(total_points, na.rm = TRUE), .groups = 'drop')

# Calculate the completion rate for each student within each domain (number of titles attempted)
completion_rate_domain <- merged_data %>%
  group_by(domain, student_ID) %>%
  summarise(titles_attempted = n_distinct(title_ID), .groups = 'drop')

# Merge all metrics for each domain
student_performance_domain <- overall_weighted_score_domain_true %>%
  left_join(completion_rate_domain, by = c("domain", "student_ID"))

```

## Identify Students with Mastery in Each Domain

Define mastery criteria and identify students who have attained mastery in each domain.

```{r}

# Determine high knowledge students within each domain based on the top 25% of the overall weighted score
high_knowledge_threshold_domain <- student_performance_domain %>%
  group_by(domain) %>%
  summarise(threshold = quantile(overall_mean_score, 0.75), .groups = 'drop')

# Merge the threshold back with the performance data
student_performance_domain <- student_performance_domain %>%
  left_join(high_knowledge_threshold_domain, by = "domain")

# Identify high knowledge students within each domain
high_knowledge_students_domain <- student_performance_domain %>%
  filter(overall_mean_score >= threshold)

# Calculate the percentage of correct answers for each student within each domain
correct_answers_domain <- merged_data %>%
  filter(state == "Absolutely_Correct") %>%
  group_by(domain, student_ID) %>%
  summarise(correct_count = n(), .groups = 'drop')

total_answers_domain <- merged_data %>%
  group_by(domain, student_ID) %>%
  summarise(total_count = n(), .groups = 'drop')

correct_percentage_domain <- correct_answers_domain %>%
  left_join(total_answers_domain, by = c("domain", "student_ID")) %>%
  mutate(correct_percentage = correct_count / total_count)

# Merge correct percentage with high knowledge students within each domain
high_knowledge_students_domain <- high_knowledge_students_domain %>%
  left_join(correct_percentage_domain, by = c("domain", "student_ID"))

# Identify high knowledge students with low correct percentage (e.g., below 50%) within each domain
low_correct_students_domain <- high_knowledge_students_domain %>%
  filter(correct_percentage < 0.5)

```

```{r}

low_correct_students_domain_id <- low_correct_students_domain$student_ID

tough_qns <- attempt_scores_domain_true %>%
  filter (student_ID %in% low_correct_students_domain_id) %>%
  filter (Never_correct == "yes")

tough_details <- df_TitleInfo %>%
  filter (title_ID %in% tough_qns$title_ID)

```

```{r}

# - high_knowledge_students_domain: high mastery students in each domain
# - merged_data: merged data of student records and question info

# Filter merged_data for high mastery students
high_mastery_attempts <- merged_data %>%
  inner_join(high_knowledge_students_domain %>% select(student_ID, domain), by = c("student_ID", "domain"))

# Identify questions never answered correctly by high mastery students within each domain
questions_never_correct <- high_mastery_attempts %>%
  group_by(domain, title_ID) %>%
  summarise(never_correct = all(state != "Absolutely_Correct"), .groups = 'drop') %>%
  filter(never_correct)

# Extract the title_IDs
titles_never_correct <- questions_never_correct %>% select(domain, title_ID)

# Display the title_IDs that were never answered correctly by high mastery students
print(titles_never_correct)

# Optional: Display additional details about these titles if needed
detailed_questions_never_correct <- merged_data %>%
  filter(title_ID %in% titles_never_correct$title_ID) %>%
  group_by(domain, title_ID) %>%
  summarise(incorrect_count = sum(state != "Absolutely_Correct"), .groups = 'drop') %>%
  arrange(desc(incorrect_count))

print(detailed_questions_never_correct)


```

```{r}
# Calculate total points and number of attempts for each student per title
attempt_scores <- merged_data %>%
  group_by(student_ID, title_ID) %>%
  summarise(total_points = sum(true_points),
            attempts = n(),
            .groups = 'drop')

# Mutate the Never_correct column
attempt_scores <- attempt_scores %>%
  mutate(Never_correct = case_when(
    total_points == -attempts ~ "yes",
    TRUE ~ "no"
  ))

# Save the attempt_scores dataframe as an RDS file
saveRDS(attempt_scores, file = "attempt_scores.RDS")

class_levels <- paste0("Class", 1:15)
domain_mastery <- merged_data %>%
  group_by(student_ID, class, domain) %>%
  summarise(average_score = mean(points), .groups = 'drop') %>%
  left_join(df_StudentInfo %>% select(student_ID, sex, age, major), by = "student_ID") %>%
  mutate(age = as.character(age)) %>%
  mutate(class = factor(class, levels = class_levels))

# Save the domain mastery dataframe as an RDS file
saveRDS(domain_mastery, file = "domain_mastery.RDS")

saveRDS(df_TitleInfo, "title_info.RDS")

```

```{r}

threshold_scores <- calculate_threshold_scores(domain_mastery, "90%")

calculate_threshold_scores <- function(domain_mastery, threshold) {
  percentile <- as.numeric(sub("%", "", threshold)) / 100
  threshold_scores <- domain_mastery %>%
    group_by(domain) %>%
    summarise(threshold_score = quantile(average_score, percentile))
  
  return(threshold_scores)
}

check <- domain_mastery %>%
    inner_join(threshold_scores, by = "domain")

get_high_mastery_students <- function(domain_mastery, threshold_scores) {
  high_mastery_students <- domain_mastery %>%
    inner_join(threshold_scores, by = "domain") %>%
    filter(average_score > threshold_score) %>%
    ungroup()
  return(high_mastery_students)
}

high_mastery_students <- get_high_mastery_students(domain_mastery, threshold_scores)

never_correct_questions <- merged_data %>%
      inner_join(high_mastery_students, by = c("student_ID", "domain", "class"), relationship = "many-to-many") %>%
      group_by(student_ID, title_ID, domain) %>%
      summarise(total_points = sum(points), attempts = n(), .groups = 'drop') %>%
      mutate(Never_correct = if_else(total_points == -attempts, "yes", "no")) %>%
      filter(Never_correct == "yes")

filtered_questions <- never_correct_questions %>%
      left_join(title_info, by = c("title_ID" = "title_ID"))
```


```{r}

calculate_threshold_scores <- function(knowledge_mastery, threshold) {
  percentile <- as.numeric(sub("%", "", threshold)) / 100
  threshold_scores <- knowledge_mastery %>%
    group_by(knowledge) %>%
    summarise(threshold_score = quantile(average_score, percentile, na.rm = TRUE))
  
  return(threshold_scores)
}

get_high_mastery_students <- function(knowledge_mastery, threshold_scores) {
  high_mastery_students <- knowledge_mastery %>%
    inner_join(threshold_scores, by = "knowledge") %>%
    filter(average_score > threshold_score) %>%
    ungroup()
  return(high_mastery_students)
}

get_low_mastery_students <- function(knowledge_mastery, low_threshold_scores) {
  low_mastery_students <- knowledge_mastery %>%
    inner_join(low_threshold_scores, by = "knowledge") %>%
    filter(average_score < threshold_score) %>%
    ungroup()
  return(low_mastery_students)
}



threshold_scores <- calculate_threshold_scores(knowledge_mastery, "99%")
    
high_mastery_students <- get_high_mastery_students(knowledge_mastery, threshold_scores)

low_threshold_scores <- calculate_threshold_scores(knowledge_mastery, "1%")

low_mastery_students <- knowledge_mastery %>%
    inner_join(low_threshold_scores, by = "knowledge")%>%
    filter(average_score < threshold_score)%>%
    ungroup()

```


```{r}
filtered_never_correct <- never_absolutely_correct %>%
      filter(student_ID %in% high_mastery_students$student_ID) %>%
      group_by(title_ID) %>%
      summarise(number_of_students = n(), .groups = 'drop') %>%
      left_join(title_info, by = "title_ID")


bottom_percentage_never_correct <- knowledge_expanded %>%
  filter(student_ID %in% low_mastery_students$student_ID) %>%
  filter(title_ID %in% filtered_never_correct$title_ID) %>%
  filter(state == "Absolutely_Correct") %>%
  distinct(student_ID, title_ID) %>%
  group_by(title_ID) %>%
  summarise(no_of_students = n(), .groups = 'drop')



```