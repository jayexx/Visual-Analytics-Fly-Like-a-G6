---
title: "Task 4: Question Difficulty & Learners Knowledge Level"
author: "Jayexx, fudi, yuhui"
date: "June 1, 2024"
date-modified: "last-modified"
execute: 
  eval: true
  echo: true
  warning: false
  freeze: true
---

## Introduction

These are the detailed steps taken for Task 4 of the project.

### Objective & Task Requirements

The key objective of Task 3 is:

-   To analyse and provide a visual representation of the alignment between question difficulty and learners knowledge level, and hence to identify inappropriate questions where high knowledge level students had a lower correct answering rate.

This would entail the following sub-task requirements:

-   To idenify high knowledge students
-   To identify any questions that these students had a lower answering rate, and also conversely find those that low knowledge level students scored better in

## Getting Started

### Loading Required R Package Libraries

The code chunk below loads the following libraries:

-   [`tidyverse`](https://www.tidyverse.org/packages/): an amalgamation of libraries for data handling (including ggplot2, dplyr, tidyr, readr, tibble)
-   `knitr`: for creating dynamic html tables/reports
-   `ggridges`: extension of ggplot2 designed for plotting ridgeline plots
-   `ggdist`: extension of ggplot2 designed for visualising distribution and uncertainty,
-   `colorspace`: provides a broad toolbox for selecting individual colors or color palettes, manipulating these colors, and employing them in various kinds of visualisations.
-   `ggrepel`: provides geoms for ggplot2 to repel overlapping text labels.
-   `ggthemes`: provides additional themes, geoms, and scales for ggplot package
-   `hrbrthemes`: provides typography-centric themes and theme components for ggplot package
-   `patchwork`: preparing composite figure created using ggplot package
-   `lubridate`: for wrangling of date-time data
-   `ggstatplot`: provides alternative statistical inference methods by default as an extension of the ggplot2 package
-   `plotly`: R library for plotting interactive statistical graphs.
-   [`rjson`](https://cran.r-project.org/web/packages/cluster/index.html): Methods for Cluster analysis.
-   [`visNetwork`](https://cran.r-project.org/web/packages/factoextra/readme/README.html#:~:text=The%20R%20package%20factoextra%20has,data%20visualization%20with%20less%20typing.): Extract and Visualize the Results of Multivariate Data Analyses.
-   [`BiocManager`](https://ggobi.github.io/ggally/): Extension of `ggplot2` by adding several functions to reduce the complexity of combining geometric objects with transformed data.
-   [`igraph`](https://ggobi.github.io/ggally/): Extension of `ggplot2` by adding several functions to reduce the complexity of combining geometric objects with transformed data.
-   cluster
-   factoextra
-   stats
-   hms
-   caret
-   ggfortify
-   gridExtra
-   GGally
-   parallelPlot
-   seriation
-   dendextend
-   heatmaply
-   corrplot
-   ggalluvial
-   entropy
-   ineq

```{r}
pacman::p_load(tidyverse, knitr, ggridges, ggdist, colorspace, ggrepel, ggthemes, hrbrthemes, patchwork, lubridate, ggstatsplot, plotly, rjson, visNetwork, BiocManager, igraph, cluster, factoextra, stats, hms, caret, ggfortify, gridExtra, GGally, parallelPlot, seriation, dendextend, heatmaply, corrplot, ggalluvial, entropy, ineq) 
```

### Importing the Data

The data for this exercise was collected from a select group of learners over a specified set of programming tasks over a particular learning period, which was compiled in 3 datasets described below. It is accompanied by a separate document providing a more detailed description of the data and variables.

-   Dataset 1: Student Information - This comprises of 5 Cols, 1364 Rows, providing individualised demographic variables of the learners (a.k.a students) within the scope this project
-   Dataset 2: Learning Subject Title Information - This comprises of 5 Cols, 44 Rows, providing variables of the questions from the programming tasks which are collated in the scope of this project
-   Dataset 3: Class Submission Records - This comprises of 15 datasets, each with 10 Cols and various number of rows, providing supposedly the participating learners' answering variables to the questions collated in the scope of this project

From the raw data, the file was cleaned, prepared and merged in the Data Preparation Steps.

The code chunk below imports the prepared dataset into R environment by using [*`read_csv()`*](https://readr.tidyverse.org/reference/read_delim.html) function of [`readr`](https://readr.tidyverse.org/), which is part of the tidyverse package.

```{r}
merged_data <- readRDS("merged_data_df.rds")

glimpse (merged_data)
```

## Metrics Selection and Computation

### For High and Low Knowledge Level Learners

Based on assessment of the given data and contextual information provided, the selected approach to identify high knowledge level learners is as follows:

-   Compute mastery points of students

Recap on Mastery Point metric from task 1:

-   Proportion of absolutely and partially correct attempts: - absolutely correct attempts - award 1 pt - partially correct attempts - award (actual_score / question_score) - normalise attempts across questions - uses (total point / total attempts)\

-   Use of more than 1 method per question - multiply by no. of methods if absolutely correct attempt submitted for that question

-   Identify the top percentile of students with the highest mastery points as high mastery students

-   Conversely, identify the bottom percentile of students with lowest mastery points as low mastery students

This is computed in the following code chunks.

```{r}
# Assign points to attempts based on state and actual score
adjusted_scores <- merged_data %>%
  mutate(points = case_when(
    state == "Absolutely_Correct" ~ 1,
    state == "Partially_Correct" ~ actual_score / question_score,
    TRUE ~ 0 # default case for any unexpected states
  ))

# Assign points to title_IDs per student factoring in normalisation and multiple methods used
mastery_scores_byQns <- adjusted_scores %>%
  group_by(student_ID, title_ID) %>%
  summarise(
    total_points = sum(points),
    total_attempts = n(),
    unique_methods = n_distinct(method),
    absolutely_correct_methods = sum(points == 1)
  ) %>%
  mutate(
    adjusted_points = total_points / total_attempts,
    adjusted_points = adjusted_points * ifelse(absolutely_correct_methods > 0, unique_methods, 1)
  )

glimpse(mastery_scores_byQns)

```

```         
# Combine the adjusted score with knowledge-transposed titleInfo dataframe
mastery_scores2 <- df_TitleInfo_gp %>%
  distinct(title_ID, .keep_all = TRUE) %>%
  left_join(mastery_scores1, by = "title_ID") %>%
  rename(knowledge = knowledge.x) %>%
  select(-score,
         -knowledge.y)
  
glimpse(mastery_scores2)
```

```{r}
# Summing up points to identify high and low mastery students
mastery_scores_byStudent <- mastery_scores_byQns %>%
  group_by(student_ID) %>%
  summarize(
    # Part (a): Sum of total points across all questions
    `Sum of points Overall` = sum(adjusted_points, na.rm = TRUE)
    
  )

glimpse(mastery_scores_byStudent)

```

Using a 95th and 5th percentile threshold, the high knowledge level (aka high mastery) and low knowledge level (aka low mastery) students are identified with the following code chunk

```{r}

calculate_threshold_scores <- function(df, column, threshold) {
  percentile <- as.numeric(sub("%", "", threshold)) / 100
  threshold_score <- quantile(df[[column]], percentile, na.rm = TRUE)
  
  return(threshold_score)
}

# Calculate threshold scores for 99% and 1%
threshold_95 <- calculate_threshold_scores(mastery_scores_byStudent, "Sum of points Overall", "95%")
threshold_5 <- calculate_threshold_scores(mastery_scores_byStudent, "Sum of points Overall", "5%")

# Filter high and low mastery students based on the threshold scores
high_mastery_students <- mastery_scores_byStudent %>%
  filter(`Sum of points Overall` > threshold_95)

low_mastery_students <- mastery_scores_byStudent %>%
  filter(`Sum of points Overall` < threshold_5)

glimpse(high_mastery_students)
glimpse(low_mastery_students)
```

### Poor correct answer rate

Based on assessment of the given data and contextual information provided, the selected metrics to identify poor correct answering rate is assessed to be as follows:

-   Never Correct Questions - Questions where a learner never gotten absolutely correct across all answers submitted
-   Error rate - percentage of wrong answer (0 score) submissions

```{r}
# Never Correct title_IDs for individual students
never_absolutely_correct <- merged_data %>%
  group_by(student_ID, title_ID) %>%
  summarise(
    never_absolutely_correct = all(state != "Absolutely_Correct"),
    .groups = 'drop'
  )  %>%
  filter(never_absolutely_correct)

# Save processed dataset
saveRDS(never_absolutely_correct, file = "never_absolutely_correct.RDS")

glimpse(never_absolutely_correct)
```

```{r}
# Calculate the error rate with consideration of different methods
percentage_error <- merged_data %>%
  group_by(student_ID, title_ID) %>%
  summarise(
    total_attempts = n(),
    wrong_attempts = sum(state != "Absolutely_Correct"),
    percentage_wrong = (wrong_attempts / total_attempts) * 100,
    .groups = 'drop'
  )

# View the result
glimpse(percentage_error)

# Save processed dataset
saveRDS(percentage_error, file = "percentage_error.RDS")

```

## Visualising Inappropriate questions

### Dumbell plot Analysis

Utilizing a dumbbell plot, we examined the discrepancies in question performance between high and low mastery students based on percentage of never correct questions.

```{r}
# Filter never absolutely correct questions based on high mastery students
filtered_never_correct <- never_absolutely_correct %>%
      filter(student_ID %in% high_mastery_students$student_ID) %>%
      distinct(student_ID, title_ID) %>%
      group_by(title_ID) %>%
      summarise(
        number_of_students = n_distinct(student_ID),
        .groups = 'drop') %>%
      mutate(percentage_of_student_wrong = (number_of_students/length(high_mastery_students$student_ID)*100)) 
    
    
# Check if bottom percentage students got the questions that were never correct by high mastery students correct
bottom_percentage_never_correct <- merged_data %>%
      filter(student_ID %in% low_mastery_students$student_ID) %>%
      filter(title_ID %in% filtered_never_correct$title_ID) %>%
      filter(state == "Absolutely_Correct") %>%
      distinct(student_ID, title_ID) %>%
      group_by(title_ID) %>%
      summarise(no_of_students = n(), .groups = 'drop') %>%
      mutate(percentage_of_student_right = (no_of_students/length(low_mastery_students$student_ID)*100))
    
glimpse(filtered_never_correct)
glimpse(bottom_percentage_never_correct)


```

```{r}
    # Calculate percentages for high mastery and low mastery students
    high_mastery_percent <- filtered_never_correct %>%
      mutate(high_mastery = number_of_students / nrow(high_mastery_students) * 100) %>%
      select (title_ID, high_mastery)

    low_mastery_percent <- bottom_percentage_never_correct %>%
      mutate(low_mastery = no_of_students / nrow(low_mastery_students) * 100) %>%
      select (title_ID, low_mastery)
    
    comparison_data <- high_mastery_percent %>%
      left_join(low_mastery_percent, by = "title_ID") %>%
      mutate(diff = round(low_mastery - high_mastery),digits = 2) %>%
      pivot_longer (cols = c(low_mastery,high_mastery)) %>%
      rename (type_of_student = name,
              percentage = value)
   
    low_mastery <-  comparison_data %>%
      filter(type_of_student == "low_mastery")
    
    high_mastery <-  comparison_data %>%
      filter(type_of_student == "high_mastery")
    
    stats <- comparison_data %>%
      group_by(type_of_student) %>%
      summarise(mean = mean(percentage),
                SE = sd(percentage)) %>%
      mutate(meanpos = mean + 1 *SE,
             meanneg = mean - 1 *SE)
    
    stats_low_mastery <- stats %>%
      filter(type_of_student == "low_mastery")
    stats_high_mastery <- stats %>%
      filter(type_of_student == "high_mastery")
    
    diff <- comparison_data %>% 
      filter(type_of_student == "low_mastery") %>%
      mutate(x_pos = percentage + (-diff/2))
    
    comparison_spread <- comparison_data %>%
      spread(type_of_student, percentage)
    
    # Join the stats to get the mean values
    comparison_spread <- comparison_spread %>%
      left_join(stats %>% filter(type_of_student == "high_mastery") %>% select(-type_of_student), by = character()) %>%
      rename(high_mastery_mean = mean, high_mastery_SE = SE, high_mastery_meanpos = meanpos, high_mastery_meanneg = meanneg) %>%
      left_join(stats %>% filter(type_of_student == "low_mastery") %>% select(-type_of_student), by = character()) %>%
      rename(low_mastery_mean = mean, low_mastery_SE = SE, low_mastery_meanpos = meanpos, low_mastery_meanneg = meanneg)
    
    # Create the color condition
    comparison_spread <- comparison_spread %>%
      mutate(color_condition = case_when(
        high_mastery > high_mastery_meanpos & low_mastery > low_mastery_meanpos ~ "red",
        TRUE ~ "default"
      ))
    
    # Gather the data back to long format
    comparison_long <- comparison_spread %>%
      gather(type_of_student, percentage, high_mastery, low_mastery) %>%
      mutate(type_of_student = factor(type_of_student, levels = c("high_mastery", "low_mastery"))) %>%
      mutate (color_condition = ifelse(color_condition == "default", type_of_student, color_condition))
    
    comparison_long$color_condition <- as.factor(comparison_long$color_condition)
```

```{r}
    # Calculate percentages for high mastery and low mastery students
    high_mastery_percent <- filtered_never_correct %>%
      mutate(high_mastery = number_of_students / nrow(high_mastery_students) * 100) %>%
      select (title_ID, high_mastery)
    
    low_mastery_percent <- bottom_percentage_never_correct %>%
      mutate(low_mastery = no_of_students / nrow(low_mastery_students) * 100) %>%
      select (title_ID, low_mastery)
    
    comparison_data <- high_mastery_percent %>%
      left_join(low_mastery_percent, by = "title_ID") %>%
      mutate(diff = round(low_mastery - high_mastery),digits = 2) %>%
      pivot_longer (cols = c(low_mastery,high_mastery)) %>%
      rename (type_of_student = name,
              percentage = value)
    
    low_mastery <-  comparison_data %>%
      filter(type_of_student == "low_mastery")
    
    high_mastery <-  comparison_data %>%
      filter(type_of_student == "high_mastery")
    
    stats <- comparison_data %>%
      group_by(type_of_student) %>%
      summarise(mean = mean(percentage),
                SE = sd(percentage)) %>%
      mutate(meanpos = mean + 1 *SE,
             meanneg = mean - 1 *SE)
    
    stats_low_mastery <- stats %>%
      filter(type_of_student == "low_mastery")
    stats_high_mastery <- stats %>%
      filter(type_of_student == "high_mastery")
    
    diff <- comparison_data %>% 
      filter(type_of_student == "low_mastery") %>%
      mutate(x_pos = percentage + (-diff/2))
    
    comparison_spread <- comparison_data %>%
      spread(type_of_student, percentage)
    
    # Join the stats to get the mean values
    comparison_spread <- comparison_spread %>%
      left_join(stats %>% filter(type_of_student == "high_mastery") %>% select(-type_of_student), by = character()) %>%
      rename(high_mastery_mean = mean, high_mastery_SE = SE, high_mastery_meanpos = meanpos, high_mastery_meanneg = meanneg) %>%
      left_join(stats %>% filter(type_of_student == "low_mastery") %>% select(-type_of_student), by = character()) %>%
      rename(low_mastery_mean = mean, low_mastery_SE = SE, low_mastery_meanpos = meanpos, low_mastery_meanneg = meanneg)
    
    # Create the color condition
    comparison_spread <- comparison_spread %>%
      mutate(color_condition = case_when(
        high_mastery > high_mastery_meanpos & low_mastery > low_mastery_meanpos ~ "red",
        TRUE ~ "default"
      ))
    
    # Gather the data back to long format
    comparison_long <- comparison_spread %>%
      gather(type_of_student, percentage, high_mastery, low_mastery) %>%
      mutate(type_of_student = factor(type_of_student, levels = c("high_mastery", "low_mastery"))) %>%
      mutate (color_condition = ifelse(color_condition == "default", type_of_student, color_condition))
    
    comparison_long$color_condition <- as.factor(comparison_long$color_condition)
```

```{r}
      ggplot(comparison_long) +
        geom_rect(xmin = stats_low_mastery$meanneg, xmax = stats_low_mastery$meanpos,
                  ymin = 0, ymax = 38, fill = "#762a83", alpha = .05) +
        geom_vline(xintercept = stats_low_mastery$mean, linetype = "solid", size = .5, alpha = .8, color = "#762a83")+
        
        geom_rect(xmin = stats_high_mastery$meanneg, xmax = stats_high_mastery$meanpos,
                  ymin = 0, ymax = 38, fill = "#009688", alpha = .05)+  
        geom_vline(xintercept = stats_high_mastery$mean, color = "#009688", linetype = "solid",  size = .5, alpha = .8) +
        
        
        geom_segment(data = low_mastery,
                     aes(x = percentage, y = title_ID,
                         yend = high_mastery$title_ID, xend = high_mastery$percentage),
                     color = "#aeb6bf",
                     size = 4.5,
                     alpha = 0.5) +
        geom_point(aes(x = percentage, y = title_ID, color = color_condition), size = 4, show.legend = TRUE) +
        #color points
        scale_color_manual(values = c("1" = "#009688", "2" = "#762a83", "red" = "red"),
                           labels = c("1" = "High Mastery Students", "2" = "Low Mastery Students")
                           ) +
        #add annotations for mean and standard deviations
        geom_text(x = stats_low_mastery$mean + 5, y = 38, label = "MEAN", angle = 90, size = 2.5, color = "#009688")+
        geom_text(x = stats_low_mastery$meanpos + 5, y = 38, label = "STDEV", angle = 90, size = 2.5, color = "#009688")+
        ggtitle("Comparison of High Mastery Student Never Correct Percentage vs Low Mastery Student Correct Percentage") +
        geom_text (data = diff,
                   aes(label = paste("D:", diff, "%"), x = x_pos, y = title_ID),
                   color = "#4a4e4d",
                   size = 2.5) +
        facet_grid(title_ID ~ ., scales = "free", switch = "y") +
        theme_minimal()+
        theme(panel.grid.major.y = element_blank(),
              panel.grid.minor.y = element_blank(),
              panel.grid.major.x = element_blank(),
              panel.grid.minor.x = element_blank(),
              axis.title.y = element_blank(),
              axis.text.y = element_blank(),
              axis.ticks.y = element_blank(),
              axis.ticks.x = element_line(color = "#4a4e4d"),
              text = element_text(family = "Segoe UI Semibold", color = "#4a4e4d"),
              strip.text.y.left  = element_text(angle = 0),
              panel.background = element_rect(fill = "white", color = "white"),
              strip.background = element_rect(fill = "white", color = "white"),
              strip.text = element_text(color = "#4a4e4d", family = "Segoe UI"),
              plot.background = element_rect(fill = "white", color = "white"),
              panel.spacing = unit(0, "lines"),
              plot.margin = margin(1,1,.5,1, "cm"))
```

### Lollipop Chart Analysis

Our subsequent analysis involved a lollipop chart to identify the error rates among high mastery students across all assessed questions.

```{r}

percentage_error <- percentage_error %>%
  filter (student_ID %in% high_mastery_students$student_ID) %>%
  group_by(title_ID) %>%
  summarise (avg_percentage_wrong = mean(percentage_wrong))

percentile_75 <- quantile(percentage_error$avg_percentage_wrong, 0.75)

percentage_error <- percentage_error %>%
  mutate(highlight = ifelse(avg_percentage_wrong > percentile_75, "Above 75 Percentile", "Below 75 Percentile"))

ggplot(percentage_error, aes(x = reorder(title_ID,avg_percentage_wrong), y = avg_percentage_wrong, color = highlight)) +
  geom_segment(aes(x = title_ID, xend = title_ID, y = 0, yend = avg_percentage_wrong), color = "grey") +
  geom_point(size = 4, alpha = 0.8) +
  scale_color_manual(values = c("Above 75 Percentile" = "red", "Below 75 Percentile" = "blue"), name = "Error Quantile") +
  labs(
    title = "Average Error Rate per Question for High Mastery Students",
    x = "Title ID",
    y = "Percentage of Error Rate"
    ) +
  theme_light() +
  coord_flip() +
  theme(
    panel.grid.major.y = element_blank(),
    panel.border = element_blank(),
    axis.ticks.y = element_blank(),    
    axis.title.y = element_text(size = 14, color = "black"),
    axis.title.x = element_text(size = 14, color = "black"),
    plot.title = element_text(size = 14, hjust = 0.5, face = "bold", color = "black"),
    legend.title = element_text(size = 10),
    legend.text = element_text(size = 10),
    legend.position = "bottom",
    panel.spacing.x = unit(2, "cm")
    )
```

By focusing on the 75th percentile of error rates, we identified several questions that frequently tripped up otherwise proficient students. Notable examples include Question_5fgqjSBwTPG7KUV3it6O and Question_YWXHr4G6Cl7bEm9iF2kQ, which consistently demonstrated higher error rates, indicating potential misalignment with the expected competencies of high mastery students. These findings highlight the need for a reassessment of these questions to ensure they accurately measure and reflect true student performance.

### Information Characteristic Curve (ICC) Analysis

Further insights were gleaned from an Information Characteristic Curve (ICC) analysis using a two-parameter Item Response Theory model to determine the degree by which questions will differentiate in performance between high and low knowledge level students.

```{R}
student_question <- merged_data %>%
  group_by(student_ID, title_ID) %>%
  summarise (count = n()) %>%
  ungroup()

student_question <- student_question %>%
  group_by(student_ID) %>%
  summarise (count = n()) %>%
  filter (count >1) %>%
  ungroup()
```

```{r}
first_attempt_data <- merged_data %>%
  group_by(student_ID, title_ID) %>%
  slice(1) %>%
  mutate (true_points = case_when(
      state == "Absolutely_Correct" ~ 1,
      TRUE ~ 0
    )) %>%
  select (student_ID, title_ID, true_points)

first_attempt_long <- pivot_wider(first_attempt_data, 
                                   names_from = title_ID, values_from = true_points) %>%
  filter (student_ID %in% student_question$student_ID)
  


```

```{r}
library (mirt)
first_attempt_long <- first_attempt_long %>%
  mutate_all(~ replace_na(., 0))

saveRDS(first_attempt_long, "mirtdata.RDS")  


first_attempt_long_high <- first_attempt_long %>%
  filter(student_ID %in% high_mastery_students$student_ID | student_ID %in% low_mastery_students$student_ID)

fit3PL <- mirt(data = first_attempt_long_high[2:39], 
               model = 1,  # alternatively, we could also just specify model = 1 in this case
               itemtype = "2PL",
               SE = TRUE,
               verbose = FALSE)
fit3PL

```

```{r}
df_IRT <- readRDS ("mirtdata.RDS")

df_IRT <- df_IRT %>%
  filter(student_ID %in% high_mastery_students$student_ID | student_ID %in% low_mastery_students$student_ID)
    
fit3PL <- mirt(data = df_IRT[2:39],
               model = 1,  # alternatively, we could also just specify model = 1 in this case
               itemtype = "2PL",
               SE = TRUE,
               verbose = FALSE)

plot(fit3PL, type = 'infotrace', which.item = c(1:38), facet_items = TRUE, 
     as.table = TRUE, auto.key = list(points = FALSE, lines = TRUE, columns = 1, space = 'right', cex = .8), 
     theta_lim = c(-3, 3), 
     main = "Item Information Curves Plot of 2PL Model",
     layout = c(10, ceiling(38 / 10)))
```

```{R}
plot(fit3PL, type = 'trace', which.item = c(1:38), facet_items = TRUE, 
     as.table = TRUE, auto.key = list(points = FALSE, lines = TRUE, columns = 1, space = 'right', cex = .8), 
     theta_lim = c(-3, 3), 
     main = "Category Characteristic Curves Plot of 2PL Model",
     layout = c(10, ceiling(38 / 10)))
```

This analysis highlighted items like Question_h7pXNg80nJbw1C4kAPRm and Question_Az73sM0rHfWVKuc4X2kL, which showed shallow gradients and did not peak at optimal probabilities. This indicates a low discrimination ability among various student abilities, underscoring the ineffectiveness of these questions in differentiating between differing levels of student mastery. Coupled with information from high mastery student ICCs, which ideally should show steeper slopes, it was confirmed that even top-performing students struggled with these questions, suggesting they are poorly suited for assessing high-level competencies.
