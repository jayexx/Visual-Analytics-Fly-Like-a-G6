{
  "hash": "cbeb1e37ae63209cb8c5e91ac738534b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Task3\"\nauthor: \"Jayexx, fudi, yuhui\"\ndate: \"June 1, 2024\"\ndate-modified: \"last-modified\"\nexecute: \n  eval: true\n  echo: true\n  warning: false\n  freeze: true\n---\n\n\n## Introduction\n\nThese are the detailed steps taken for Task 3 of the project.\n\n### Objective & Task Requirements\n\nThe key objective of Task 3 is:\n\n-   To analyse and provide a visual representation of the relationship between learning modes and knowledge acquisition (learners' ability to absorb, integrate, and apply knowledge)\n\nThis would entail the following sub-task requirements:\n\n-   To visualise and uncover the various learning modes, and\n-   To visualise and uncover the patterns in distribution in learner's performance in each various learning modes, and\n-   To visualise and determine the statistical differences and correlations that learning mode may have with learners' performance\n\n## Getting Started\n\n### Loading Required R Package Libraries\n\nThe code chunk below loads the following libraries:\n\n-   [`tidyverse`](https://www.tidyverse.org/packages/): an amalgamation of libraries for data handling (including ggplot2, dplyr, tidyr, readr, tibble)\n-   `knitr`: for creating dynamic html tables/reports\n-   `ggridges`: extension of ggplot2 designed for plotting ridgeline plots\n-   `ggdist`: extension of ggplot2 designed for visualising distribution and uncertainty,\n-   `colorspace`: provides a broad toolbox for selecting individual colors or color palettes, manipulating these colors, and employing them in various kinds of visualisations.\n-   `ggrepel`: provides geoms for ggplot2 to repel overlapping text labels.\n-   `ggthemes`: provides additional themes, geoms, and scales for ggplot package\n-   `hrbrthemes`: provides typography-centric themes and theme components for ggplot package\n-   `patchwork`: preparing composite figure created using ggplot package\n-   `lubridate`: for wrangling of date-time data\n-   `ggstatplot`: provides alternative statistical inference methods by default as an extension of the ggplot2 package\n-   `plotly`: R library for plotting interactive statistical graphs.\n-   [`rjson`](https://cran.r-project.org/web/packages/cluster/index.html): Methods for Cluster analysis.\n-   [`visNetwork`](https://cran.r-project.org/web/packages/factoextra/readme/README.html#:~:text=The%20R%20package%20factoextra%20has,data%20visualization%20with%20less%20typing.): Extract and Visualize the Results of Multivariate Data Analyses.\n-   [`BiocManager`](https://ggobi.github.io/ggally/): Extension of `ggplot2` by adding several functions to reduce the complexity of combining geometric objects with transformed data.\n-   [`igraph`](https://ggobi.github.io/ggally/): Extension of `ggplot2` by adding several functions to reduce the complexity of combining geometric objects with transformed data.\n-   cluster\n-   factoextra\n-   stats\n-   hms\n-   caret\n-   ggfortify\n-   gridExtra\n-   GGally\n-   parallelPlot\n-   seriation\n-   dendextend\n-   heatmaply\n-   corrplot\n-   ggalluvial\n-   entropy\n-   ineq\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(tidyverse, knitr, ggridges, ggdist, colorspace, ggrepel, ggthemes, hrbrthemes, patchwork, lubridate, ggstatsplot, plotly, rjson, visNetwork, BiocManager, igraph, cluster, factoextra, stats, hms, caret, ggfortify, gridExtra, GGally, parallelPlot, seriation, dendextend, heatmaply, corrplot, ggalluvial, entropy, ineq) \n```\n:::\n\n\n### Importing the Data\n\nThe data for this exercise was collected from a select group of learners over a specified set of programming tasks over a particular learning period, which was compiled in 3 datasets described below. It is accompanied by a separate document providing a more detailed description of the data and variables.\n\n-   Dataset 1: Student Information - This comprises of 5 Cols, 1364 Rows, providing individualised demographic variables of the learners (a.k.a students) within the scope this project\n-   Dataset 2: Learning Subject Title Information - This comprises of 5 Cols, 44 Rows, providing variables of the questions from the programming tasks which are collated in the scope of this project\n-   Dataset 3: Class Submission Records - This comprises of 15 datasets, each with 10 Cols and various number of rows, providing supposedly the participating learners' answering variables to the questions collated in the scope of this project\n\nFrom the raw data, the file was cleaned, prepared and merged in the Data Preparation Steps.\n\nThe code chunk below imports the prepared dataset into R environment by using [*`read_csv()`*](https://readr.tidyverse.org/reference/read_delim.html) function of [`readr`](https://readr.tidyverse.org/), which is part of the tidyverse package.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmerged_data <- readRDS(\"merged_data_df.rds\")\n\nglimpse (merged_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 232,811\nColumns: 39\n$ title_ID       <chr> \"Question_3MwAFlmNO8EKrpY5zjUd\", \"Question_3MwAFlmNO8EK…\n$ student_ID     <chr> \"d554e419f820fa5cb0ca\", \"b92448e12093e45dc6ff\", \"6b2292…\n$ class          <chr> \"Class9\", \"Class8\", \"Class12\", \"Class7\", \"Class1\", \"Cla…\n$ time           <dbl> 1696330917, 1699625054, 1697444103, 1695964704, 1697727…\n$ state          <chr> \"Partially_Correct\", \"Partially_Correct\", \"Error1\", \"Pa…\n$ actual_score   <dbl> 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1…\n$ method         <chr> \"Method_BXr9AIsPQhwNvyGdZL57\", \"Method_BXr9AIsPQhwNvyGd…\n$ memory         <dbl> 196, 332, 0, 196, 0, 0, 336, 320, 324, 204, 340, 320, 3…\n$ timeconsume    <dbl> 2, 6, 2, 3, 4, 3, 4, 4, 2, 2, 3, 5, 3, 4, 3, 5, 1, 3, 3…\n$ time_change    <dttm> 2023-10-03 04:09:22, 2023-11-10 07:11:39, 2023-10-16 0…\n$ sex            <chr> \"male\", \"female\", \"female\", \"male\", \"male\", \"male\", \"ma…\n$ age            <dbl> 19, 21, 23, 20, 21, 20, 19, 20, 21, 21, 21, 21, 21, 21,…\n$ major          <chr> \"J40192\", \"J23517\", \"J87654\", \"J87654\", \"J40192\", \"J401…\n$ b3C9s_j0v1yls8 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ b3C9s_l4z6od7y <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ g7R2j_e0v1yls8 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ g7R2j_j1g8gd3v <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ k4W1c_h5r6nux7 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ m3D1v_r1d7fr3l <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ m3D1v_t0v5ts9h <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ m3D1v_v3d9is1x <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ r8S3g_l0p5viby <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ r8S3g_n0m9rsw4 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ s8Y2f_v4x8by9j <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ t5V9e_e1k6cixp <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ y9W5d_c0w4mj5h <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ y9W5d_e2j7p95s <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ y9W5d_p8g6dgtv <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ b3C9s          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ g7R2j          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ k4W1c          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ m3D1v          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ r8S3g          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ s8Y2f          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ t5V9e          <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ y9W5d          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ question_score <dbl> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2…\n$ knowledge      <chr> \"t5V9e\", \"t5V9e\", \"t5V9e\", \"t5V9e\", \"t5V9e\", \"t5V9e\", \"…\n$ sub_knowledge  <chr> \"t5V9e_e1k6cixp\", \"t5V9e_e1k6cixp\", \"t5V9e_e1k6cixp\", \"…\n```\n\n\n:::\n:::\n\n\n## Learning modes\n\nBased on the given data, the relevant features that best defines a learner's learning mode is assessed to be as follows:\n\n-   Peak answering hours determined by (a) day of the week and (b) time of the day\n-   Variety of question types attempted determined by (a) total number of different questions attempted, (b) total number of different knowledge and sub knowledge areas covered,\n-   Depth of question types and answers determined by (a) mean question scores, (b) mean memory size of file submissions across questions\n-   Level of learning effort determined by (a) total number of answering attempts, (b) average number of different answering methods used across questions, (C) total memory size of file submission\n-   Categorical preferences\n\n### Feature engineering\n\n#### Peak answering hours Boolean Integer Variables\n\nSplitting Date and time up from the earlier created time_change date-time variable, and adding 2 derived variables for boolean integer values for weekday (Mon to Fri) and working hours (8am to 8pm) with the following code chunk.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmerged_data_lm <- merged_data %>%\n  mutate(\n    date = as.Date(time_change),\n    time = as_hms(format(time_change, \"%H:%M:%S\")),\n    is_weekday = as.numeric(wday(date) %in% 2:6),  # Monday to Friday 1, else 0\n    is_working_hours = as.numeric(hour(time) >= 8 & hour(time) < 20)  # 8am to 8pm 1, else 0\n  )\n\nglimpse(merged_data_lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 232,811\nColumns: 42\n$ title_ID         <chr> \"Question_3MwAFlmNO8EKrpY5zjUd\", \"Question_3MwAFlmNO8…\n$ student_ID       <chr> \"d554e419f820fa5cb0ca\", \"b92448e12093e45dc6ff\", \"6b22…\n$ class            <chr> \"Class9\", \"Class8\", \"Class12\", \"Class7\", \"Class1\", \"C…\n$ time             <time> 04:09:22, 07:11:39, 01:22:28, 22:25:49, 08:11:04, 02…\n$ state            <chr> \"Partially_Correct\", \"Partially_Correct\", \"Error1\", \"…\n$ actual_score     <dbl> 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 1, 0, 1, 1, 0, 1, 0, 1,…\n$ method           <chr> \"Method_BXr9AIsPQhwNvyGdZL57\", \"Method_BXr9AIsPQhwNvy…\n$ memory           <dbl> 196, 332, 0, 196, 0, 0, 336, 320, 324, 204, 340, 320,…\n$ timeconsume      <dbl> 2, 6, 2, 3, 4, 3, 4, 4, 2, 2, 3, 5, 3, 4, 3, 5, 1, 3,…\n$ time_change      <dttm> 2023-10-03 04:09:22, 2023-11-10 07:11:39, 2023-10-16…\n$ sex              <chr> \"male\", \"female\", \"female\", \"male\", \"male\", \"male\", \"…\n$ age              <dbl> 19, 21, 23, 20, 21, 20, 19, 20, 21, 21, 21, 21, 21, 2…\n$ major            <chr> \"J40192\", \"J23517\", \"J87654\", \"J87654\", \"J40192\", \"J4…\n$ b3C9s_j0v1yls8   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ b3C9s_l4z6od7y   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ g7R2j_e0v1yls8   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ g7R2j_j1g8gd3v   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ k4W1c_h5r6nux7   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ m3D1v_r1d7fr3l   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ m3D1v_t0v5ts9h   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ m3D1v_v3d9is1x   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ r8S3g_l0p5viby   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ r8S3g_n0m9rsw4   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ s8Y2f_v4x8by9j   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ t5V9e_e1k6cixp   <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ y9W5d_c0w4mj5h   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ y9W5d_e2j7p95s   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ y9W5d_p8g6dgtv   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ b3C9s            <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ g7R2j            <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ k4W1c            <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ m3D1v            <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ r8S3g            <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ s8Y2f            <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ t5V9e            <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ y9W5d            <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ question_score   <dbl> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,…\n$ knowledge        <chr> \"t5V9e\", \"t5V9e\", \"t5V9e\", \"t5V9e\", \"t5V9e\", \"t5V9e\",…\n$ sub_knowledge    <chr> \"t5V9e_e1k6cixp\", \"t5V9e_e1k6cixp\", \"t5V9e_e1k6cixp\",…\n$ date             <date> 2023-10-03, 2023-11-10, 2023-10-16, 2023-09-28, 2023…\n$ is_weekday       <dbl> 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,…\n$ is_working_hours <dbl> 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,…\n```\n\n\n:::\n:::\n\n\n#### Group By Student ID\n\nThe following variables will be obtained with the code chunk below in preparation for clustering analysis\n\n-   Peak answering hours\n\n  (a) percentage of answers on weekdays,\n  (b) percentage of answers during working hours\n\n-   Variety of question types attempted\n\n  (a) total number of different questions attempted,\n  (b) total number of different knowledge and sub knowledge areas covered,\n\n-   Depth of question types\n\n  (a) mean question scores,\n  (b) mean memory size of file submissions across questions\n  (c) mean time consume across questions\n\n-   Level of learning effort in answers submitted\n\n  (a) total number of answering attempts,\n  (b) average number of different answering methods used across questions,\n  (c) total memory size of file submission\n  (d) total time consume for answers submitted\n\n\n::: {.cell}\n\n```{.r .cell-code}\nStudentLM_data <- merged_data_lm %>%\n  group_by(student_ID) %>%\n  summarize(\n    `Percent of submissions on weekdays` = sum(is_weekday, na.rm = TRUE) / n() * 100,\n    `Percent of submissions during working hrs` = sum(is_working_hours, na.rm = TRUE) / n() * 100,\n    `Total no. of different qns_attempted` = n_distinct(title_ID, na.rm = TRUE),\n    `Gini Index for qns in submission` = Gini(table(title_ID)),\n    `Span of different knowledge in qns` = sum(colSums(across(29:36, as.numeric)) > 0),\n    `Span of different sub knowledge in qns` = sum(colSums(across(14:28, as.numeric)) > 0),\n    `Mean selected question scores` = mean(question_score, na.rm = TRUE),\n    `Mean submission memory size by qns` = mean(sapply(split(memory, title_ID), mean, na.rm = TRUE), na.rm = TRUE),\n    `Mean timeconsume by qns` = mean(sapply(split(timeconsume, title_ID), mean, na.rm = TRUE), na.rm = TRUE),\n    `Total no. of submissions` = n(),\n    `Mean no. of different answering methods per qns` = mean(sapply(split(method, title_ID), function(x) n_distinct(x, na.rm = TRUE)), na.rm = TRUE),\n    `Gini index for answering methods used per qns` = Gini(table(method)),\n    `Total memory size of submissions` = sum(memory, na.rm = TRUE),\n    `Total timeconsume of submissions` = sum(timeconsume, na.rm = TRUE)\n  )\n\nglimpse(StudentLM_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 1,364\nColumns: 15\n$ student_ID                                        <chr> \"0088dc183f73c83f763…\n$ `Percent of submissions on weekdays`              <dbl> 94.88372, 88.75000, …\n$ `Percent of submissions during working hrs`       <dbl> 14.883721, 10.416667…\n$ `Total no. of different qns_attempted`            <int> 38, 38, 38, 38, 38, …\n$ `Gini Index for qns in submission`                <dbl> 0.47380661, 0.395175…\n$ `Span of different knowledge in qns`              <int> 8, 8, 8, 8, 8, 8, 8,…\n$ `Span of different sub knowledge in qns`          <int> 15, 15, 15, 15, 15, …\n$ `Mean selected question scores`                   <dbl> 2.339535, 2.266667, …\n$ `Mean submission memory size by qns`              <dbl> 249.1707, 419.3248, …\n$ `Mean timeconsume by qns`                         <dbl> 3.543709, 12.390546,…\n$ `Total no. of submissions`                        <int> 215, 240, 478, 119, …\n$ `Mean no. of different answering methods per qns` <dbl> 2.815789, 3.289474, …\n$ `Gini index for answering methods used per qns`   <dbl> 0.04279070, 0.070000…\n$ `Total memory size of submissions`                <dbl> 48164, 97820, 136496…\n$ `Total timeconsume of submissions`                <dbl> 802, 2583, 9814, 415…\n```\n\n\n:::\n:::\n\n\n#### Univariate Analysis of features\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define the function to create combined box plot and histogram\ncreate_combined_plot <- function(data, variable) {\n  ggplot(data, aes_string(x = paste0(\"`\", variable, \"`\"))) +\n    # Histogram\n    geom_histogram(aes(y = ..density..), bins = 30, fill = \"skyblue\", color = \"black\", alpha = 0.7) +\n    geom_density(alpha = 0.3, fill = \"orange\") +\n    # Box plot\n    geom_boxplot(aes(y = 0), width = 0.1, color = \"red\", position = position_nudge(y = -0.1)) +\n    theme_minimal() +\n    labs(x = variable, y = \"Density\") +\n    ggtitle(paste(\"Combined Histogram and Box Plot for\", variable))\n}\n\n\n# Variables to plot\nvariables <- names(StudentLM_data)[2:15]\n\n# Create combined plots for each variable\nplots <- lapply(variables, function(var) create_combined_plot(StudentLM_data, var))\n\n# Display the plots\nfor (p in plots) {\n  print(p)\n}\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-5-1.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-5-2.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-5-3.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-5-4.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-5-5.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-5-6.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-5-7.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-5-8.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-5-9.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-5-10.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-5-11.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-5-12.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-5-13.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-5-14.png){width=1440}\n:::\n:::\n\n\n#### Check for high colinearity\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSLM.cor <- cor(StudentLM_data[, 2:15])\n\ncorrplot(SLM.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-6-1.png){width=1440}\n:::\n\n```{.r .cell-code}\nggstatsplot::ggcorrmat(\n  data = StudentLM_data, \n  cor.vars = 2:15)\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-6-2.png){width=1440}\n:::\n:::\n\n\n#### Removing highly skewed and correlated columns\n\nBased on the output from the univariate and correlation analysis, 2 variables were found to be highly skewed and concentrated within 1 or 2 values, hence they are removed for more meaningful analysis, with the following code chunk. For high correlation with a threshold of \\>0.8, 3 variables were found to be highly correlated, of which, 2 have been removed as highly skewed, leaving total_different_questions_attempted in the data frame.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nStudentLM_data <- StudentLM_data %>%\n  select(-`Span of different knowledge in qns`, \n#         -`Total timeconsume of submissions`, \n#         -`Total memory size of submissions`, \n#         -`Total no. of submissions`, \n#         -`Mean no. of different answering methods per qns`, \n#         -`Gini index for answering methods used per qns`, \n#         -`Total no. of different qns_attempted`, \n         -`Span of different sub knowledge in qns`)\n\nglimpse(StudentLM_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 1,364\nColumns: 13\n$ student_ID                                        <chr> \"0088dc183f73c83f763…\n$ `Percent of submissions on weekdays`              <dbl> 94.88372, 88.75000, …\n$ `Percent of submissions during working hrs`       <dbl> 14.883721, 10.416667…\n$ `Total no. of different qns_attempted`            <int> 38, 38, 38, 38, 38, …\n$ `Gini Index for qns in submission`                <dbl> 0.47380661, 0.395175…\n$ `Mean selected question scores`                   <dbl> 2.339535, 2.266667, …\n$ `Mean submission memory size by qns`              <dbl> 249.1707, 419.3248, …\n$ `Mean timeconsume by qns`                         <dbl> 3.543709, 12.390546,…\n$ `Total no. of submissions`                        <int> 215, 240, 478, 119, …\n$ `Mean no. of different answering methods per qns` <dbl> 2.815789, 3.289474, …\n$ `Gini index for answering methods used per qns`   <dbl> 0.04279070, 0.070000…\n$ `Total memory size of submissions`                <dbl> 48164, 97820, 136496…\n$ `Total timeconsume of submissions`                <dbl> 802, 2583, 9814, 415…\n```\n\n\n:::\n:::\n\n\nNoting that there would be complex interaction of these features that could eventually shape a learners’ knowledge acquisition, coupled with the fact that there would be varying levels of each feature present in each learner, it was concluded that cluster analysis of the aforementioned features across the students would provide the most meaningful relationship between learning mode patterns and knowledge acquisition of learners.\n\n### Number of K-Means clusters\n\nTo determine the ideal number of clusters for K-means clustering on the recompiled learners' learning mode features, a silhouette analysis and SSE elbow method are performed in the following code chunks.\n\n#### Silhouette analysis\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Exclude non-numeric columns\nStudentLM_data_numeric <- StudentLM_data %>%\n  select(-student_ID)\n\n# Function to compute silhouette widths\nsilhouette_analysis <- function(data, max_clusters) {\n  avg_sil_widths <- numeric(max_clusters)\n  \n  for (k in 2:max_clusters) {\n    # Perform k-means clustering\n    kmeans_result <- kmeans(data, centers = k, nstart = 25)\n    \n    # Compute silhouette widths\n    sil <- silhouette(kmeans_result$cluster, dist(data))\n    \n    # Calculate average silhouette width\n    avg_sil_widths[k] <- mean(sil[, 3])\n  }\n  \n  return(avg_sil_widths)\n}\n\n# Determine the maximum number of clusters to test\nmax_clusters <- 12\n\n# Perform silhouette analysis\navg_sil_widths <- silhouette_analysis(StudentLM_data_numeric, max_clusters)\n\n# Plot the average silhouette widths\nplot(1:max_clusters, avg_sil_widths, type = \"b\", pch = 19, frame = FALSE,\n     xlab = \"Number of clusters\", ylab = \"Average silhouette width\",\n     main = \"Silhouette Analysis for Determining Optimal Number of Clusters\")\n\n# Highlight the optimal number of clusters\noptimal_clusters <- which.max(avg_sil_widths)\npoints(optimal_clusters, avg_sil_widths[optimal_clusters], col = \"red\", pch = 19)\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n#### SSE-Elbow method\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function to compute SSE for different numbers of clusters\ncompute_sse <- function(data, max_clusters) {\n  sse <- numeric(max_clusters)\n  \n  for (k in 1:max_clusters) {\n    # Perform k-means clustering\n    kmeans_result <- kmeans(data, centers = k, nstart = 25)\n    \n    # Compute SSE\n    sse[k] <- kmeans_result$tot.withinss\n  }\n  \n  return(sse)\n}\n\n# Determine the maximum number of clusters to test\nmax_clusters <- 18\n\n# Compute SSE for each number of clusters\nsse_values <- compute_sse(StudentLM_data_numeric, max_clusters)\n\n# Plot SSE against number of clusters\nplot(1:max_clusters, sse_values, type = \"b\", pch = 19, frame = FALSE,\n     xlab = \"Number of clusters\", ylab = \"SSE\",\n     main = \"Elbow Method for Optimal Number of Clusters\")\n\n# Add text for elbow point\nelbow_point <- which.min(diff(sse_values)) + 1\ntext(elbow_point, sse_values[elbow_point], labels = paste(\"Elbow Point:\", elbow_point), pos = 4, col = \"red\")\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n### K Means clustering and Visualisation\n\nK Means clustering is then performed on the recompiled learners' learning mode features with the number of clusters set as 2 based on the above results, in the following code chunk\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Drop the student_ID column\nclustering_data <- StudentLM_data %>%\n  select(-student_ID)\n\n# Standardize the data\nclustering_data_scaled <- scale(clustering_data)\n\n# Perform k-means clustering\nset.seed(123)  # For reproducibility\nkmeans_result <- kmeans(clustering_data_scaled, centers = 2, nstart = 25)\n\n# Add the cluster assignments to the original data\nStudentLM_data$cluster <- kmeans_result$cluster\n```\n:::\n\n\nThe first plot for visualisation of the K means cluster is the Principal Component Analysis (PCA) Plot, which gives an initial sensing of the separation of the clusters based on first 2 PCA components that rank the highest in distinctness amongst the features used. This is plotted with the following code chunk.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Perform PCA\npca_result <- prcomp(StudentLM_data[-1], scale. = TRUE)\n\n# Get PCA scores\npca_scores <- as.data.frame(predict(pca_result))\n\n# Add cluster information to PCA scores\npca_scores$cluster <- factor(StudentLM_data$cluster)\n\n# Plot PCA results with cluster color coding\npca_plot <- ggplot(pca_scores, aes(PC1, PC2, color = cluster)) +\n  geom_point(size = 3) +\n  scale_color_discrete(name = \"Cluster\") +\n  labs(x = \"Principal Component 1\", y = \"Principal Component 2\",\n       title = \"PCA Plot of Clusters\") +\n  theme_minimal()\n\n# Display the plot\npca_plot\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nBased on the PCA plot, the clusters are visually clearly separated, suggesting that the clusters are distinct, especially in relation to the top 2 PCA components in the x and y-axis.\n\nNext to visualise the distribution of the 2 clusters across all the features used for the K Means clustering, a parallel coordinate plot is used, with the following code chunk.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nStudentLM_data_factor <- StudentLM_data\nStudentLM_data_factor$cluster <- as.character(StudentLM_data_factor$cluster)\n\nggparcoord(data = StudentLM_data_factor,\n           columns = c(2:13), \n           groupColumn = 14,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of Students' learning modes\")+\n  theme(\n    plot.title = element_text(size = 20),\n    axis.text.x = element_text(angle = 30, hjust = 0.8, size = 18),\n    axis.text.y = element_text(size = 18),\n    axis.title.x = element_text(size = 18),\n    axis.title.y = element_text(size = 18),\n    legend.title = element_text(size = 18),\n    legend.text = element_text(size = 18)\n    )\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-12-1.png){width=2400}\n:::\n\n```{.r .cell-code}\nggparcoord(data = StudentLM_data_factor,\n           columns = c(2:13), \n           groupColumn = 14,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Split Plot of Students' learning modes\")+\n  facet_wrap(~ cluster)+\n  theme(\n    plot.title = element_text(size = 20),\n    axis.text.x = element_text(angle = 30, hjust = 0.8, size = 18),\n    axis.text.y = element_text(size = 18),\n    axis.title.x = element_text(size = 18),\n    axis.title.y = element_text(size = 18),\n    legend.title = element_text(size = 18),\n    legend.text = element_text(size = 18)\n    )\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-12-2.png){width=2400}\n:::\n:::\n\n\nBased on the plot, there is varying degree of distinction in separation between the 2 clusters across different variables. The more distinct separation are in variables such as total timeconsume of answers, total memory size of answers, mean different answering methods per question, total answering attempts and question selection gini index, where cluster 2 tends to fare better in these metrics suggesting that perhaps cluster 2 may be the more hardworking learning mode among the 2.\n\nAn Alluvial plot is also used in the following code chunk for an alternative visualisation of the clustering, where variables are binned into 5 equally sized bins based on distribution of student_ID.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define a function to bin numerical variables based on the distribution of student_IDs\nbin_variable_equal_ids <- function(x, bins = 5) {\n  n <- length(x)\n  quantile_ranks <- ceiling(rank(x, ties.method = \"first\") / (n / bins))\n  as.factor(quantile_ranks)\n}\n\n# Apply the binning function to numerical columns, excluding student_ID and cluster\nStudentLM_data_binned <- StudentLM_data %>%\n  mutate(across(-c(student_ID, cluster), ~ bin_variable_equal_ids(., bins = 5)))\n\n# Convert data to long format\nStudentLM_data_long <- StudentLM_data_binned %>%\n  pivot_longer(cols = -c(student_ID, cluster), names_to = \"variable\", values_to = \"value\")\n\n# Check rows with NA values\nStudentLM_data_checkNA <- StudentLM_data_long %>%\n  filter(if_any(everything(), ~ is.na(.)))\n\nglimpse(StudentLM_data_checkNA)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 0\nColumns: 4\n$ student_ID <chr> \n$ cluster    <int> \n$ variable   <chr> \n$ value      <fct> \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Ensure the 'cluster' variable is in discrete values (1 and 2)\nStudentLM_data_long <- StudentLM_data_long %>%\n  mutate(cluster = as.factor(cluster))\n\n# Ensure there are no NA values in the cluster column\nStudentLM_data_long <- StudentLM_data_long %>%\n  filter(!is.na(cluster))\n\n# Create the alluvial plot\nggplot(StudentLM_data_long,\n       aes(x = variable, stratum = value, alluvium = student_ID)) +\n#  geom_flow(stat = \"alluvium\", lode.guidance = \"forward\", color = \"white\") +\n  geom_alluvium(aes(fill = cluster)) +\n  geom_stratum() +\n  scale_x_discrete(limits = unique(StudentLM_data_long$variable), expand = c(0.5, 0.1)) +\n  theme_minimal() +\n  labs(title = \"Alluvial Plot of Learning Mode Clusters\",\n       x = \"Variables\",\n       y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8))        \n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-14-1.png){width=2400}\n:::\n\n```{.r .cell-code}\n#        axis.text.y = element_text(size = 8),        plot.title = element_text(size = 12),        legend.title = element_text(size = 10),        legend.text = element_text(size = 8),        axis.title.x = element_text(size = 10),        axis.title.y = element_text(size = 10),        plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n```\n:::\n\n\n### Number of clusters and method for Hierarchical Clustering\n\nAs an alternative to K means, hierarchical clustering is also considered, and initiates with mapping the data frame into a data matrix, and thereby using the dend_expend function to determine the best clustering method.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nStudentLM_data1 <- StudentLM_data  %>%\n  select(-cluster) \n#  mutate(across(everything(), scale))\n\nrow.names(StudentLM_data1) <- StudentLM_data$student_ID\n#StudentLM_data1 <- select(StudentLM_data1, c(1, 2:13))\nStudentLM_data_matrix1 <- data.matrix(StudentLM_data1)\n\nStudentLM_data_d1 <- dist(\n  normalize(StudentLM_data_matrix1[, -c(1)]), \n  method = \"euclidean\")\ndend_expend(StudentLM_data_d1)[[3]]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.2669653\n2      unknown        ward.D2 0.3637016\n3      unknown         single 0.7571795\n4      unknown       complete 0.5926958\n5      unknown        average 0.8032403\n6      unknown       mcquitty 0.6096951\n7      unknown         median 0.6870881\n8      unknown       centroid 0.7422864\n```\n\n\n:::\n:::\n\n\nBased on the output above, the average method will be the most optimal.\n\nA silhoutte plot in the same approach as before is also done with the following code chunk to determine the optimal number of clusters to achieve higher distinction in cluster separation for hierarchical clustering.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nStudentLM_data_clust <- hclust(StudentLM_data_d1, method = \"average\")\nnum_k <- find_k(StudentLM_data_clust)\nplot(num_k)\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\nBased on the output above, 9 clusters were identified to be optimal in terms of distinction in separation.\n\n### Hierarchical Clustering and Visualisation\n\nNow using the 2 parameters, the hierarchical clustering using the same visualisations of PCA, Parallel Coordinate Plots and Alluvial Plots are created with the following code chunks.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Cut the tree into a 9 clusters\ncluster_cut <- cutree(StudentLM_data_clust, k = 9)\n\n# Add the cluster assignment to the data\nStudentLM_data1_n <- normalize(StudentLM_data1)\n\nStudentLM_data1_n$cluster_hc <- as.factor(cluster_cut)\n\nglimpse(StudentLM_data1_n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 1,364\nColumns: 14\n$ student_ID                                        <chr> \"0088dc183f73c83f763…\n$ `Percent of submissions on weekdays`              <dbl> 0.9488372, 0.8875000…\n$ `Percent of submissions during working hrs`       <dbl> 0.14883721, 0.104166…\n$ `Total no. of different qns_attempted`            <dbl> 1.0000000, 1.0000000…\n$ `Gini Index for qns in submission`                <dbl> 0.66600804, 0.555479…\n$ `Mean selected question scores`                   <dbl> 0.6515011, 0.6160606…\n$ `Mean submission memory size by qns`              <dbl> 0.15476836, 0.288330…\n$ `Mean timeconsume by qns`                         <dbl> 0.05099268, 0.406939…\n$ `Total no. of submissions`                        <dbl> 0.25330132, 0.283313…\n$ `Mean no. of different answering methods per qns` <dbl> 0.51492537, 0.649253…\n$ `Gini index for answering methods used per qns`   <dbl> 0.16432955, 0.294312…\n$ `Total memory size of submissions`                <dbl> 0.06864675, 0.139881…\n$ `Total timeconsume of submissions`                <dbl> 0.043706487, 0.14211…\n$ cluster_hc                                        <fct> 1, 1, 1, 1, 1, 1, 1,…\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Perform PCA\npca_result <- prcomp(StudentLM_data1_n[, -c(1, 14)], scale = FALSE)\npca_df <- as.data.frame(pca_result$x[, 1:2])  # Example: Extracting the first two principal components\n\n# Add cluster information to PCA scores\npca_scores$cluster_hc <- factor(StudentLM_data1_n$cluster_hc)\n\n# Plot PCA with cluster_hc\nggplot(pca_df, aes(x = PC1, y = PC2, color = factor(StudentLM_data1_n$cluster_hc))) +\n  geom_point() +\n  labs(title = \"PCA Plot with Clustering\", x = \"Principal Component 1\", y = \"Principal Component 2\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggparcoord(data = StudentLM_data1_n, \n           columns = c(2:13), \n           groupColumn = 14,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of Students' learning modes\")+\n   theme(axis.text.x = element_text(angle = 30))\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-19-1.png){width=2400}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define a function to bin numerical variables based on the distribution of student_IDs\nbin_variable_equal_ids <- function(x, bins = 5) {\n  n <- length(x)\n  quantile_ranks <- ceiling(rank(x, ties.method = \"first\") / (n / bins))\n  as.factor(quantile_ranks)\n}\n\n# Apply the binning function to numerical columns, excluding student_ID and cluster\nStudentLM_data_binned1 <- StudentLM_data1_n %>%\n  mutate(across(-c(student_ID, cluster_hc), ~ bin_variable_equal_ids(., bins = 5)))\n\n# Convert data to long format\nStudentLM_data_long1 <- StudentLM_data_binned1 %>%\n  pivot_longer(cols = -c(student_ID, cluster_hc), names_to = \"variable\", values_to = \"value\")\n\n# Check rows with NA values\nStudentLM_data_checkNA <- StudentLM_data_long1 %>%\n  filter(if_any(everything(), ~ is.na(.)))\n\nglimpse(StudentLM_data_checkNA)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 0\nColumns: 4\n$ student_ID <chr> \n$ cluster_hc <fct> \n$ variable   <chr> \n$ value      <fct> \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Ensure the 'cluster' variable is in discrete values (1 and 2)\nStudentLM_data_long1 <- StudentLM_data_long1 %>%\n  mutate(cluster_hc = as.factor(cluster_hc))\n\n# Ensure there are no NA values in the cluster column\nStudentLM_data_long1 <- StudentLM_data_long1 %>%\n  filter(!is.na(cluster_hc))\n\n# Create the alluvial plot\nggplot(StudentLM_data_long1,\n       aes(x = variable, stratum = value, alluvium = student_ID)) +\n#  geom_flow(stat = \"alluvium\", lode.guidance = \"forward\", color = \"white\") +\n  geom_alluvium(aes(fill = cluster_hc)) +\n  geom_stratum() +\n  scale_x_discrete(limits = unique(StudentLM_data_long$variable), expand = c(0.5, 0.1)) +\n  theme_minimal() +\n  labs(title = \"Alluvial Plot of Learning Mode Clusters\",\n       x = \"Variables\",\n       y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8),\n        axis.text.y = element_text(size = 8),\n        plot.title = element_text(size = 12),\n        legend.title = element_text(size = 10),\n        legend.text = element_text(size = 8),\n        axis.title.x = element_text(size = 10),\n        axis.title.y = element_text(size = 10),\n        plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-21-1.png){width=2400}\n:::\n:::\n\n\nFrom the plots above, it can be observed that although hierarchical clustering could give a higher number of optimum clusters, the separation and distinction, is much worse in comparison with the optimum of 2 clusters using K-means. Hence for subsequent analysis, the K-means clustering results will be used instead.\n\n## Knowledge Acquisition\n\nBased on the given data, the relevant features that best defines a learner's knowledge acquisition is assessed to be as follows:\n\n-   Knowledge mastery determined by (a) overall sum of highest actual score for each question attempted, (b) sum of highest actual score of each question by knowledge area \n-   Knowledge mastery determined by combined metric defined in Task 1, (a) overall total mastery points, (d) sum of mastery points by knowledge area\n-   correct answering rate determined by (a) percentage of answers absolutely correct, (b) total number of questions with answers absolutely correct and partially correct\n\n\n### Feature engineering\n\n#### Group By Student ID\n\nThe following variables will be obtained with the code chunks below in preparation for visualisation and analysis of Knowledge Acquisition with respect to the various learning modes.\n\n-   Knowledge mastery by actual score\n\n(a) overall sum of highest actual score for each question attempted and\n(b) sum of highest actual score of each question by knowledge area\n\n-   Knowledge mastery by mastery points\n\nRecap on Mastery Point metric from task 1:\n\n  -   Proportion of absolutely and partially correct attempts:\n    -   absolutely correct attempts - award 1 pt \n    -   partially correct attempts - award (actual_score / question_score) \n    -   normalise attempts across questions - uses (total point / total attempts)\\\n  -   Use of more than 1 method per question - multiply by no. of methods if absolutely correct attempt submitted for that question\n\n(a) overall total mastery points\n(b) sum of mastery points by knowledge group\n\n-   Correct answering rate\n\n(a) percentage of answers absolutely correct,\n(b) total number of questions with answers absolutely correct and partially correct\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nStudentKA_data <- merged_data %>%\n  group_by(student_ID) %>%\n  summarize(\n    # Part (a): Sum of highest actual score for each question attempted\n    `Sum of overall highest submission scores` = sum(sapply(unique(title_ID), function(x) {\n      max(merged_data[merged_data$title_ID == x & merged_data$student_ID == cur_group()$student_ID, \"actual_score\"])\n    })),\n    \n    # Part (b): Sum of highest actual score for each knowledge area\n    `Sum of overall highest submission scores for b3C9s knowledge` = sum(sapply(unique(title_ID), function(x) {\n      max(merged_data[merged_data$title_ID == x & merged_data$student_ID == cur_group()$student_ID, \"actual_score\"] * merged_data[merged_data$title_ID == x & merged_data$student_ID == cur_group()$student_ID, 29])\n    })),\n    `Sum of overall highest submission scores for g7R2j knowledge` = sum(sapply(unique(title_ID), function(x) {\n      max(merged_data[merged_data$title_ID == x & merged_data$student_ID == cur_group()$student_ID, \"actual_score\"] * merged_data[merged_data$title_ID == x & merged_data$student_ID == cur_group()$student_ID, 30])\n    })),\n    `Sum of overall highest submission scores for k4W1c knowledge` = sum(sapply(unique(title_ID), function(x) {\n      max(merged_data[merged_data$title_ID == x & merged_data$student_ID == cur_group()$student_ID, \"actual_score\"] * merged_data[merged_data$title_ID == x & merged_data$student_ID == cur_group()$student_ID, 31])\n    })),\n    `Sum of overall highest submission scores for m3D1v knowledge` = sum(sapply(unique(title_ID), function(x) {\n      max(merged_data[merged_data$title_ID == x & merged_data$student_ID == cur_group()$student_ID, \"actual_score\"] * merged_data[merged_data$title_ID == x & merged_data$student_ID == cur_group()$student_ID, 32])\n    })),\n    `Sum of overall highest submission scores for r8S3g knowledge` = sum(sapply(unique(title_ID), function(x) {\n      max(merged_data[merged_data$title_ID == x & merged_data$student_ID == cur_group()$student_ID, \"actual_score\"] * merged_data[merged_data$title_ID == x & merged_data$student_ID == cur_group()$student_ID, 33])\n    })),\n    `Sum of overall highest submission scores for s8Y2f knowledge` = sum(sapply(unique(title_ID), function(x) {\n      max(merged_data[merged_data$title_ID == x & merged_data$student_ID == cur_group()$student_ID, \"actual_score\"] * merged_data[merged_data$title_ID == x & merged_data$student_ID == cur_group()$student_ID, 34])\n    })),\n    `Sum of overall highest submission scores for t5V9e knowledge` = sum(sapply(unique(title_ID), function(x) {\n      max(merged_data[merged_data$title_ID == x & merged_data$student_ID == cur_group()$student_ID, \"actual_score\"] * merged_data[merged_data$title_ID == x & merged_data$student_ID == cur_group()$student_ID, 35])\n    })),\n    `Sum of overall highest submission scores for y9W5d knowledge` = sum(sapply(unique(title_ID), function(x) {\n      max(merged_data[merged_data$title_ID == x & merged_data$student_ID == cur_group()$student_ID, \"actual_score\"] * merged_data[merged_data$title_ID == x & merged_data$student_ID == cur_group()$student_ID, 36])\n    })),\n    \n    # Part (c): Percentage of answers absolutely correct\n    `Percent of submissions absolutely correct` = (sum(state == \"Absolutely_Correct\") / n()) * 100,\n    \n    # Part (d): Total number of questions with answers absolutely correct and partially correct\n    `No. of questions answered fully or partially correct` = length(unique(title_ID[state %in% c(\"Partially_Correct\", \"Absolutely_Correct\")]))\n    \n  )\n\n\nglimpse(StudentKA_data)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Assign points to attempts based on state\nadjusted_scores <- merged_data %>%\n  mutate(points = case_when(\n    state == \"Absolutely_Correct\" ~ 1,\n    state == \"Partially_Correct\" ~ actual_score / question_score,\n    TRUE ~ 0 # default case for any unexpected states\n  ))\n\n# Assign points to title_IDs per student factoring in normalisation and multiple methods used\nmastery_scores1 <- adjusted_scores %>%\n  group_by(student_ID, title_ID, knowledge, class) %>%\n  summarise(\n    total_points = sum(points),\n    total_attempts = n(),\n    unique_methods = n_distinct(method),\n    absolutely_correct_methods = sum(points == 1)\n  ) %>%\n  mutate(\n    adjusted_points = total_points / total_attempts,\n    adjusted_points = adjusted_points * ifelse(absolutely_correct_methods > 0, unique_methods, 1)\n  )\n\nglimpse(mastery_scores1)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(mastery_scores1$knowledge)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Combine the adjusted score with knowledge-transposed titleInfo dataframe\nmastery_scores2 <- df_TitleInfo_gp %>%\n  distinct(title_ID, .keep_all = TRUE) %>%\n  left_join(mastery_scores1, by = \"title_ID\") %>%\n  rename(knowledge = knowledge.x) %>%\n  select(-score,\n         -knowledge.y)\n  \nglimpse(mastery_scores2)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Summing up points for Overall and Specific Knowledge Mastery for each Student\nmastery_scores <- mastery_scores2 %>%\n  group_by(student_ID) %>%\n  summarize(\n    # Part (a): Sum of total points across all questions\n    `Sum of points Overall` = sum(adjusted_points),\n    \n    # Part (b): Sum of highest actual score for each knowledge area\n    `Sum of points for b3C9s knowledge` = sum(case_when(\n      b3C9s == 1 ~ adjusted_points,\n      TRUE ~ 0\n    )),\n    \n    `Sum of points for g7R2j knowledge` = sum(case_when(\n      g7R2j == 1 ~ adjusted_points,\n      TRUE ~ 0\n    )),\n    \n    `Sum of points for k4W1c knowledge` = sum(case_when(\n      k4W1c == 1 ~ adjusted_points,\n      TRUE ~ 0\n    )),\n    \n    `Sum of points for m3D1v knowledge` = sum(case_when(\n      m3D1v == 1 ~ adjusted_points,\n      TRUE ~ 0\n    )),\n    \n    `Sum of points for r8S3g knowledge` = sum(case_when(\n      r8S3g == 1 ~ adjusted_points,\n      TRUE ~ 0\n    )),\n    \n    `Sum of points for s8Y2f knowledge` = sum(case_when(\n      s8Y2f == 1 ~ adjusted_points,\n      TRUE ~ 0\n    )),\n    \n    `Sum of points for t5V9e knowledge` = sum(case_when(\n      t5V9e == 1 ~ adjusted_points,\n      TRUE ~ 0\n    )),\n    \n    `Sum of points for y9W5d knowledge` = sum(case_when(\n      y9W5d == 1 ~ adjusted_points,\n      TRUE ~ 0\n    ))\n    \n  )\n\nglimpse(mastery_scores)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compiling the knowledge acquisition metrics\nStudentKA_data_merged <- left_join(StudentKA_data, mastery_scores, by = \"student_ID\")\n\nsaveRDS(StudentKA_data_merged, \"StudentKA_data_merged.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nStudentKA_data_merged <- read_rds(\"StudentKA_data_merged.rds\")\n\nglimpse(StudentKA_data_merged)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 1,364\nColumns: 21\n$ student_ID                                                     <chr> \"0088dc…\n$ `Sum of overall highest submission scores`                     <dbl> 100, 10…\n$ `Sum of overall highest submission scores for b3C9s knowledge` <dbl> 10, 10,…\n$ `Sum of overall highest submission scores for g7R2j knowledge` <dbl> 15, 15,…\n$ `Sum of overall highest submission scores for k4W1c knowledge` <dbl> 3, 3, 3…\n$ `Sum of overall highest submission scores for m3D1v knowledge` <dbl> 36, 36,…\n$ `Sum of overall highest submission scores for r8S3g knowledge` <dbl> 5, 5, 5…\n$ `Sum of overall highest submission scores for s8Y2f knowledge` <dbl> 3, 3, 3…\n$ `Sum of overall highest submission scores for t5V9e knowledge` <dbl> 10, 10,…\n$ `Sum of overall highest submission scores for y9W5d knowledge` <dbl> 33, 33,…\n$ `Percent of submissions absolutely correct`                    <dbl> 20.9302…\n$ `No. of questions answered fully or partially correct`         <int> 38, 38,…\n$ `Sum of points Overall`                                        <dbl> 38.7568…\n$ `Sum of points for b3C9s knowledge`                            <dbl> 3.00000…\n$ `Sum of points for g7R2j knowledge`                            <dbl> 6.74242…\n$ `Sum of points for k4W1c knowledge`                            <dbl> 1.16666…\n$ `Sum of points for m3D1v knowledge`                            <dbl> 14.0000…\n$ `Sum of points for r8S3g knowledge`                            <dbl> 4.04700…\n$ `Sum of points for s8Y2f knowledge`                            <dbl> 0.95238…\n$ `Sum of points for t5V9e knowledge`                            <dbl> 3.96739…\n$ `Sum of points for y9W5d knowledge`                            <dbl> 11.6666…\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define the function to create combined box plot and histogram\ncreate_combined_plot <- function(data, variable) {\n  ggplot(data, aes_string(x = paste0(\"`\", variable, \"`\"))) +\n    # Histogram\n    geom_histogram(aes(y = ..density..), bins = 30, fill = \"skyblue\", color = \"black\", alpha = 0.7) +\n    geom_density(alpha = 0.3, fill = \"orange\") +\n    # Box plot\n    geom_boxplot(aes(y = 0), width = 0.1, color = \"red\", position = position_nudge(y = -0.1)) +\n    theme_minimal() +\n    labs(x = variable, y = \"Density\") +\n    ggtitle(paste(\"Combined Histogram and Box Plot for\", variable))\n}\n\n\n# Variables to plot\nvariables <- names(StudentKA_data_merged)[2:21]\n\n# Create combined plots for each variable\nplots <- lapply(variables, function(var) create_combined_plot(StudentKA_data_merged, var))\n\n# Display the plots\nfor (p in plots) {\n  print(p)\n}\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-29-1.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-29-2.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-29-3.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-29-4.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-29-5.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-29-6.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-29-7.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-29-8.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-29-9.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-29-10.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-29-11.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-29-12.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-29-13.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-29-14.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-29-15.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-29-16.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-29-17.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-29-18.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-29-19.png){width=1440}\n:::\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-29-20.png){width=1440}\n:::\n:::\n\n\n### Merging Students' Learning Modes with Knowledge Acqusition features\n\nWith the both data frames prepared, they will now be merged for the next sub-task which involves comparison of learners' knowledge acquisition with respect to learning mode, and subsequently to identify patterns and relationships.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Join the two dataframes on the column student_ID\nStudentLMKA_data <- left_join(StudentLM_data, StudentKA_data_merged, by = \"student_ID\")\n\nglimpse(StudentLMKA_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 1,364\nColumns: 34\n$ student_ID                                                     <chr> \"0088dc…\n$ `Percent of submissions on weekdays`                           <dbl> 94.8837…\n$ `Percent of submissions during working hrs`                    <dbl> 14.8837…\n$ `Total no. of different qns_attempted`                         <int> 38, 38,…\n$ `Gini Index for qns in submission`                             <dbl> 0.47380…\n$ `Mean selected question scores`                                <dbl> 2.33953…\n$ `Mean submission memory size by qns`                           <dbl> 249.170…\n$ `Mean timeconsume by qns`                                      <dbl> 3.54370…\n$ `Total no. of submissions`                                     <int> 215, 24…\n$ `Mean no. of different answering methods per qns`              <dbl> 2.81578…\n$ `Gini index for answering methods used per qns`                <dbl> 0.04279…\n$ `Total memory size of submissions`                             <dbl> 48164, …\n$ `Total timeconsume of submissions`                             <dbl> 802, 25…\n$ cluster                                                        <int> 1, 2, 2…\n$ `Sum of overall highest submission scores`                     <dbl> 100, 10…\n$ `Sum of overall highest submission scores for b3C9s knowledge` <dbl> 10, 10,…\n$ `Sum of overall highest submission scores for g7R2j knowledge` <dbl> 15, 15,…\n$ `Sum of overall highest submission scores for k4W1c knowledge` <dbl> 3, 3, 3…\n$ `Sum of overall highest submission scores for m3D1v knowledge` <dbl> 36, 36,…\n$ `Sum of overall highest submission scores for r8S3g knowledge` <dbl> 5, 5, 5…\n$ `Sum of overall highest submission scores for s8Y2f knowledge` <dbl> 3, 3, 3…\n$ `Sum of overall highest submission scores for t5V9e knowledge` <dbl> 10, 10,…\n$ `Sum of overall highest submission scores for y9W5d knowledge` <dbl> 33, 33,…\n$ `Percent of submissions absolutely correct`                    <dbl> 20.9302…\n$ `No. of questions answered fully or partially correct`         <int> 38, 38,…\n$ `Sum of points Overall`                                        <dbl> 38.7568…\n$ `Sum of points for b3C9s knowledge`                            <dbl> 3.00000…\n$ `Sum of points for g7R2j knowledge`                            <dbl> 6.74242…\n$ `Sum of points for k4W1c knowledge`                            <dbl> 1.16666…\n$ `Sum of points for m3D1v knowledge`                            <dbl> 14.0000…\n$ `Sum of points for r8S3g knowledge`                            <dbl> 4.04700…\n$ `Sum of points for s8Y2f knowledge`                            <dbl> 0.95238…\n$ `Sum of points for t5V9e knowledge`                            <dbl> 3.96739…\n$ `Sum of points for y9W5d knowledge`                            <dbl> 11.6666…\n```\n\n\n:::\n:::\n\n\n### Visualisation of Knowledge Aquisition by learning mode clusters\n\nTo visualise differences in the performance in total number of questions that had correct or partially correct answers, a ridgeline plot is utilised to compare the shape of distribution of students in both clusters on the same axes, using the following code chunk.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nStudentLMKA_data$cluster <- as.factor(StudentLMKA_data$cluster)\n\n# Plot\nggplot(StudentLMKA_data, \n       aes(x = `No. of questions answered fully or partially correct`, \n           y = cluster,\n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-31-1.png){width=1152}\n:::\n\n```{.r .cell-code}\nggplot(StudentLMKA_data, \n       aes(x = `Sum of points Overall`, \n           y = cluster,\n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-31-2.png){width=1152}\n:::\n:::\n\n\nCluster 2 has a sharper peak and more packed to the right which suggests that students in this cluster generally performed better, while for cluster 1 there is a 2nd smaller group of that performs even worse.\n\nA multi faceted plot to compare the distribution of answering performance based on *mastery points* in respect to the 2 clusters across 6 knowledge areas is plotted with the following code chunk.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#| fig-width: 12\n#| fig-height: 7\n\n#a <- \nggplot(StudentLMKA_data, \n       aes(x = `Sum of points for b3C9s knowledge`,\n           y = cluster,\n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#b <- \nggplot(StudentLMKA_data, \n       aes(x = `Sum of points for g7R2j knowledge`,\n           y = cluster,\n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-32-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#c <- \nggplot(StudentLMKA_data, \n       aes(x = `Sum of points for m3D1v knowledge`, \n           y = cluster,\n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-32-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#d <- \n  ggplot(StudentLMKA_data, \n       aes(x = `Sum of points for r8S3g knowledge`, \n           y = cluster,\n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-32-4.png){width=672}\n:::\n\n```{.r .cell-code}\n#e <- \n  ggplot(StudentLMKA_data, \n       aes(x = `Sum of points for t5V9e knowledge`, \n           y = cluster,\n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-32-5.png){width=672}\n:::\n\n```{.r .cell-code}\n#f <- \n  ggplot(StudentLMKA_data, \n       aes(x = `Sum of points for y9W5d knowledge`, \n           y = cluster,\n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-32-6.png){width=672}\n:::\n\n```{.r .cell-code}\n#g <- \nggplot(StudentLMKA_data, \n       aes(x = `Sum of points for k4W1c knowledge`, \n           y = cluster,\n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-32-7.png){width=672}\n:::\n\n```{.r .cell-code}\n#h <- \n  ggplot(StudentLMKA_data, \n       aes(x = `Sum of points for s8Y2f knowledge`, \n           y = cluster,\n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-32-8.png){width=672}\n:::\n\n```{.r .cell-code}\n#(a + b) / (c + d) / (e + f) / (g + h)\n```\n:::\n\n\n\nA multi faceted plot to compare the distribution of answering performance based on *highest actual score* in respect to the 2 clusters across 6 knowledge areas is also plotted with the following code chunk.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#a <- \n  ggplot(StudentLMKA_data, \n       aes(x = `Sum of overall highest submission scores for b3C9s knowledge`, \n           y = cluster,\n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-33-1.png){width=1152}\n:::\n\n```{.r .cell-code}\n#b <- \n  ggplot(StudentLMKA_data, \n       aes(x = `Sum of overall highest submission scores for g7R2j knowledge`,\n           y = cluster,\n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-33-2.png){width=1152}\n:::\n\n```{.r .cell-code}\n#c <- \n  ggplot(StudentLMKA_data, \n       aes(x = `Sum of overall highest submission scores for m3D1v knowledge`,\n           y = cluster,\n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-33-3.png){width=1152}\n:::\n\n```{.r .cell-code}\n#d <- \n  ggplot(StudentLMKA_data, \n       aes(x = `Sum of overall highest submission scores for r8S3g knowledge`, \n           y = cluster,\n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-33-4.png){width=1152}\n:::\n\n```{.r .cell-code}\n#e <- \n  ggplot(StudentLMKA_data, \n       aes(x = `Sum of overall highest submission scores for t5V9e knowledge`, \n           y = cluster,\n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-33-5.png){width=1152}\n:::\n\n```{.r .cell-code}\n#f <- \n  ggplot(StudentLMKA_data, \n       aes(x = `Sum of overall highest submission scores for y9W5d knowledge`, \n           y = cluster,\n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-33-6.png){width=1152}\n:::\n\n```{.r .cell-code}\n#g <- \n  ggplot(StudentLMKA_data, \n       aes(x = `Sum of overall highest submission scores for k4W1c knowledge`, \n           y = cluster,\n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-33-7.png){width=1152}\n:::\n\n```{.r .cell-code}\n#h <- \n  ggplot(StudentLMKA_data, \n       aes(x = `Sum of overall highest submission scores for s8Y2f knowledge`, \n           y = cluster,\n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-33-8.png){width=1152}\n:::\n\n```{.r .cell-code}\n#(a + b) / (c + d) / (e + f) / (g + h)\n```\n:::\n\n\nThe findings are highly congruent with the earlier ridge plost, which found that cluster 2 had performed better with a sharper peak and more concentration of learners to the right, where as cluster 1 had small pockets of learners to the left instead.\n\nA statistical violin plot to perform both a mathematical 2 sample mean test in tandem with a visual analysis of the difference in the distribution of the students' total actual score in the answering records in respect of the 2 clusters is plot with the following code chunk.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggbetweenstats(\n  data = StudentLMKA_data,\n  x = cluster, \n  y = `Sum of overall highest submission scores`,\n  type = \"np\",\n  messages = FALSE\n)\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n\nBased on the figures, the p-value is extremely small which suggest that there is strong statistical significance between the 2 clusters in the performance of total actual score of students in each cluster, wherein cluster 2 fared better than cluster 1, it also shows that cluster 2 is much smaller than cluster 1.\n\nLastly a similar statistical violin plot to analyse the differences in percentage of answers that were absolutely correct in respect of the 2 clusters is plot in the following code chunk.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggbetweenstats(\n  data = StudentLMKA_data,\n  x = cluster, \n  y = `Percent of submissions absolutely correct`,\n  type = \"np\",\n  messages = FALSE\n)\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-35-1.png){width=672}\n:::\n:::\n\n\nBased on the figures, the p-value is extremely small which suggest that there is strong statistical significance between the 2 clusters in the performance of total actual score of students in each cluster, wherein surprisingly, cluster 1 had fared better than cluster 2, cluster 2 had a smaller spread and more concentrated compared to cluster 1.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggbetweenstats(\n  data = StudentLMKA_data,\n  x = cluster, \n  y = `Sum of points Overall`,\n  type = \"np\",\n  messages = FALSE\n)\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-36-1.png){width=672}\n:::\n:::\n\n\n## Bivariate and Multivariate analysis of variables\n\nAs an alternative perspective, the learning mode features are now plot on a multi linear regression model against the knowledge acquistion features of highest actual score and mastery points in the following code chunks.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Multi linear regression model for sum_highest_actual_score and sum_points overall\nmodel1 <- lm(`Sum of overall highest submission scores` ~ \n               `Percent of submissions on weekdays`+\n               `Percent of submissions during working hrs`+\n               `Total no. of different qns_attempted`+\n               `Gini Index for qns in submission`+\n               `Mean selected question scores`+\n               `Mean submission memory size by qns`+\n               `Mean timeconsume by qns`+\n               `Total no. of submissions`+\n               `Mean no. of different answering methods per qns`+\n               `Gini index for answering methods used per qns`+\n               `Total memory size of submissions`+\n               `Total timeconsume of submissions`, data = StudentLMKA_data)\nmodel2 <- lm(`Sum of points Overall` ~  \n               `Percent of submissions on weekdays`+\n               `Percent of submissions during working hrs`+\n               `Total no. of different qns_attempted`+\n               `Gini Index for qns in submission`+\n               `Mean selected question scores`+\n               `Mean submission memory size by qns`+\n               `Mean timeconsume by qns`+\n               `Total no. of submissions`+\n               `Mean no. of different answering methods per qns`+\n               `Gini index for answering methods used per qns`+\n               `Total memory size of submissions`+\n               `Total timeconsume of submissions`, data = StudentLMKA_data)\n\n\nggcoefstats(model1, \n            output = \"plot\") +\n  theme(\n    plot.title = element_text(size = 22),\n    axis.title = element_text(size = 20),\n    axis.text = element_text(size = 20),\n    legend.title = element_text(size = 22),\n    legend.text = element_text(size = 20)\n  )\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-37-1.png){width=1728}\n:::\n\n```{.r .cell-code}\nggcoefstats(model2, \n            output = \"plot\") +\n    theme(\n    plot.title = element_text(size = 22),\n    axis.title = element_text(size = 20),\n    axis.text = element_text(size = 20),\n    legend.title = element_text(size = 22),\n    legend.text = element_text(size = 20)\n  )\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-37-2.png){width=1728}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel3 <- lm(`Sum of points for b3C9s knowledge` ~  \n               `Percent of submissions on weekdays`+\n               `Percent of submissions during working hrs`+\n               `Total no. of different qns_attempted`+\n               `Gini Index for qns in submission`+\n               `Mean selected question scores`+\n               `Mean submission memory size by qns`+\n               `Mean timeconsume by qns`+\n               `Total no. of submissions`+\n               `Mean no. of different answering methods per qns`+\n               `Gini index for answering methods used per qns`+\n               `Total memory size of submissions`+\n               `Total timeconsume of submissions`, data = StudentLMKA_data)\nmodel4 <- lm(`Sum of points for g7R2j knowledge` ~ \n               `Percent of submissions on weekdays`+\n               `Percent of submissions during working hrs`+\n               `Total no. of different qns_attempted`+\n               `Gini Index for qns in submission`+\n               `Mean selected question scores`+\n               `Mean submission memory size by qns`+\n               `Mean timeconsume by qns`+\n               `Total no. of submissions`+\n               `Mean no. of different answering methods per qns`+\n               `Gini index for answering methods used per qns`+\n               `Total memory size of submissions`+\n               `Total timeconsume of submissions`, data = StudentLMKA_data)\nmodel5 <- lm(`Sum of points for k4W1c knowledge` ~  \n               `Percent of submissions on weekdays`+\n               `Percent of submissions during working hrs`+\n               `Total no. of different qns_attempted`+\n               `Gini Index for qns in submission`+\n               `Mean selected question scores`+\n               `Mean submission memory size by qns`+\n               `Mean timeconsume by qns`+\n               `Total no. of submissions`+\n               `Mean no. of different answering methods per qns`+\n               `Gini index for answering methods used per qns`+\n               `Total memory size of submissions`+\n               `Total timeconsume of submissions`, data = StudentLMKA_data)\nmodel6 <- lm(`Sum of points for m3D1v knowledge` ~  \n               `Percent of submissions on weekdays`+\n               `Percent of submissions during working hrs`+\n               `Total no. of different qns_attempted`+\n               `Gini Index for qns in submission`+\n               `Mean selected question scores`+\n               `Mean submission memory size by qns`+\n               `Mean timeconsume by qns`+\n               `Total no. of submissions`+\n               `Mean no. of different answering methods per qns`+\n               `Gini index for answering methods used per qns`+\n               `Total memory size of submissions`+\n               `Total timeconsume of submissions`, data = StudentLMKA_data)\nmodel7 <- lm(`Sum of points for r8S3g knowledge` ~ \n               `Percent of submissions on weekdays`+\n               `Percent of submissions during working hrs`+\n               `Total no. of different qns_attempted`+\n               `Gini Index for qns in submission`+\n               `Mean selected question scores`+\n               `Mean submission memory size by qns`+\n               `Mean timeconsume by qns`+\n               `Total no. of submissions`+\n               `Mean no. of different answering methods per qns`+\n               `Gini index for answering methods used per qns`+\n               `Total memory size of submissions`+\n               `Total timeconsume of submissions`, data = StudentLMKA_data)\nmodel8 <- lm(`Sum of points for s8Y2f knowledge` ~  \n               `Percent of submissions on weekdays`+\n               `Percent of submissions during working hrs`+\n               `Total no. of different qns_attempted`+\n               `Gini Index for qns in submission`+\n               `Mean selected question scores`+\n               `Mean submission memory size by qns`+\n               `Mean timeconsume by qns`+\n               `Total no. of submissions`+\n               `Mean no. of different answering methods per qns`+\n               `Gini index for answering methods used per qns`+\n               `Total memory size of submissions`+\n               `Total timeconsume of submissions`, data = StudentLMKA_data)\nmodel9 <- lm(`Sum of points for t5V9e knowledge` ~  \n               `Percent of submissions on weekdays`+\n               `Percent of submissions during working hrs`+\n               `Total no. of different qns_attempted`+\n               `Gini Index for qns in submission`+\n               `Mean selected question scores`+\n               `Mean submission memory size by qns`+\n               `Mean timeconsume by qns`+\n               `Total no. of submissions`+\n               `Mean no. of different answering methods per qns`+\n               `Gini index for answering methods used per qns`+\n               `Total memory size of submissions`+\n               `Total timeconsume of submissions`, data = StudentLMKA_data)\nmodel10 <- lm(`Sum of points for y9W5d knowledge` ~ \n               `Percent of submissions on weekdays`+\n               `Percent of submissions during working hrs`+\n               `Total no. of different qns_attempted`+\n               `Gini Index for qns in submission`+\n               `Mean selected question scores`+\n               `Mean submission memory size by qns`+\n               `Mean timeconsume by qns`+\n               `Total no. of submissions`+\n               `Mean no. of different answering methods per qns`+\n               `Gini index for answering methods used per qns`+\n               `Total memory size of submissions`+\n               `Total timeconsume of submissions`, data = StudentLMKA_data)\n\n#a <- \n  ggcoefstats(model3, \n            output = \"plot\")\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-38-1.png){width=1728}\n:::\n\n```{.r .cell-code}\n#b <- \n  ggcoefstats(model4, \n            output = \"plot\")\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-38-2.png){width=1728}\n:::\n\n```{.r .cell-code}\n#c <- \n  ggcoefstats(model5, \n            output = \"plot\")\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-38-3.png){width=1728}\n:::\n\n```{.r .cell-code}\n#d <- \n  ggcoefstats(model6, \n            output = \"plot\")\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-38-4.png){width=1728}\n:::\n\n```{.r .cell-code}\n#e <- \n  ggcoefstats(model7, \n            output = \"plot\")\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-38-5.png){width=1728}\n:::\n\n```{.r .cell-code}\n#f <- \n  ggcoefstats(model8, \n            output = \"plot\")\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-38-6.png){width=1728}\n:::\n\n```{.r .cell-code}\n#g <- \n  ggcoefstats(model9, \n            output = \"plot\")\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-38-7.png){width=1728}\n:::\n\n```{.r .cell-code}\n#h <- \n  ggcoefstats(model10, \n            output = \"plot\")\n```\n\n::: {.cell-output-display}\n![](Task3_files/figure-html/unnamed-chunk-38-8.png){width=1728}\n:::\n\n```{.r .cell-code}\n#(a + b) / (c + d) / (e + f) / (g + h) \n```\n:::\n\n\n## Conclusion\n\nIn conclusion, the visual analysis of learning modes clustering found that 2 substantially distinct clusters can be formed using the selected students' learning mode features, whereby cluster 2 tends to be the more earnest learning mode cluster.\n\nUsing these clusters to draw a relationship with indicators of students' knowledge acquistion found that \n\n(1) attempting questions over a wider span of questions and different knowledge, \n(2) attempting more demanding questions that required more effort, \n(3) applying more effort in answer attempts were congruent with knowledge acquisition in terms of higher scores, higher proportion of correct submissions and the use of more answering methods, especially for knowledge in g7R2j, m3D1v, t5V9e and y9W5. Furthermore, we also discovered that, \n(4) applying a more evenly spread effort across questions and \n(5) attempting higher scoring questions had a statistically more significant effect on overall points and scores.\n",
    "supporting": [
      "Task3_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}